Nature;Titre;Auteur;Co_Auteurs;Date;URL;Texte;Nb commentaires
Reddit;tate;flyingcatwithhorns;;2024/01/10;https://www.reddit.com//r/facepalm/comments/193dxyv/tate/;;1445
Reddit;The end result is amazing but I can't wrap my head around as how someone can live like that;WorldlyBlackberry819;;2024/01/10;https://www.reddit.com//r/mildlyinfuriating/comments/193c1l3/the_end_result_is_amazing_but_i_cant_wrap_my_head/;;3707
Reddit;Rep. Jasmine Crockett has run out of patience;ExactlySorta;;2024/01/10;https://www.reddit.com//r/WhitePeopleTwitter/comments/193eixy/rep_jasmine_crockett_has_run_out_of_patience/;;238
Reddit;Five years ago my brother donated his bone marrow to cure my leukemia. We traveled together this summer! Thanks to his gift we can grow up together;Zerocare;;2024/01/10;https://www.reddit.com//r/MadeMeSmile/comments/193bmr2/five_years_ago_my_brother_donated_his_bone_marrow/;;177
Reddit;Anthony Borges used his body to shut door from a gunman, protecting 20 classmates. Fully recovered;nooneknowsme9;;2024/01/10;https://www.reddit.com//r/pics/comments/1938djd/anthony_borges_used_his_body_to_shut_door_from_a/;;1348
Reddit;Trump vowed he‚Äôd ‚Äònever‚Äô help Europe if it‚Äôs attacked, top EU official says;anangrytree;;2024/01/10;https://www.reddit.com//r/worldnews/comments/193bk1v/trump_vowed_hed_never_help_europe_if_its_attacked/;;1098
Reddit;Dude was throwing food all over himüò≠;aliteck;;2024/01/10;https://www.reddit.com//r/StupidFood/comments/193bkbx/dude_was_throwing_food_all_over_him/;;1161
Reddit;Freddie Mercury and David Bowie at Live Aid, 1985;gregornot;;2024/01/10;https://www.reddit.com//r/BeAmazed/comments/1938bl9/freddie_mercury_and_david_bowie_at_live_aid_1985/;;787
Reddit;TIL about Esmie Tseng. She endured parental abuse despite having top marks in school, often getting punished by standing naked in the corner for grades such as 96%. In 2005, she murdered her mother with a butcher knife. Later, she was tried as an adult and ultimately served six years in prison.;Saca312;;2024/01/10;https://www.reddit.com//r/todayilearned/comments/193cduf/til_about_esmie_tseng_she_endured_parental_abuse/;;515
Reddit;I was obsessed with the mid 19th century as kid;NahkaNahka;;2024/01/10;https://www.reddit.com//r/blunderyears/comments/193ewnc/i_was_obsessed_with_the_mid_19th_century_as_kid/;The last two were historical themed events, but I also just dressed like this outside sometimes.;225
Reddit;The One;kantieno;;2024/01/10;https://www.reddit.com//r/comics/comments/1936qex/the_one/;;262
Reddit;This cuts real deep;InitialDifficultys;;2024/01/10;https://www.reddit.com//r/perfectlycutscreams/comments/193dn2u/this_cuts_real_deep/;;141
Reddit;The switch up is crazy ;Mr_Muda_Himself_V3;;2024/01/10;https://www.reddit.com//r/whenthe/comments/193arpy/the_switch_up_is_crazy/;;345
Reddit;Trump Says He Wants the Economy to Crash Because It Will Hurt Biden;mountaintop111;;2024/01/10;https://www.reddit.com//r/politics/comments/193812j/trump_says_he_wants_the_economy_to_crash_because/;;978
Reddit;Think before you tweet;thexbeatboxer;;2024/01/10;https://www.reddit.com//r/clevercomebacks/comments/1936rwe/think_before_you_tweet/;;1212
Reddit;When you work in two jobs;cursed_homer;;2024/01/10;https://www.reddit.com//r/Unexpected/comments/193c798/when_you_work_in_two_jobs/;;80
Reddit;Cheerful assistant;Umer_-;;2024/01/10;https://www.reddit.com//r/gifs/comments/193c335/cheerful_assistant/;;56
Reddit;Robin Williams was insanely talented, in this interview he is asked to explain how his mind works and the answer is hilarious.;fernandollb;;2024/01/10;https://www.reddit.com//r/funny/comments/1937jim/robin_williams_was_insanely_talented_in_this/;;696
Reddit;She got her revenge ;Adventure84;;2024/01/10;https://www.reddit.com//r/SipsTea/comments/19396x9/she_got_her_revenge/;;505
Reddit;Lauren Boebert's ex-husband arrested after Colorado restaurant row;nahbruh27;;2024/01/10;https://www.reddit.com//r/news/comments/1937d8m/lauren_boeberts_exhusband_arrested_after_colorado/;;1310
Reddit;Season 2024 Cinematic;PleutreLoL;;2024/01/10;https://www.reddit.com//r/leagueoflegends/comments/1939y8q/season_2024_cinematic/;;1736
Reddit;Should have called Pornhub quickies;luxusbuerg;;2024/01/10;https://www.reddit.com//r/shitposting/comments/1939k9s/should_have_called_pornhub_quickies/;;231
Reddit;Hunter Biden walks out on Marjorie Taylor Greene;itsreallyreallytrue;;2024/01/10;https://www.reddit.com//r/PublicFreakout/comments/193bx07/hunter_biden_walks_out_on_marjorie_taylor_greene/;;999
Reddit;How did he teach them to not follow their babies?;AgeLeading9189;;2024/01/10;https://www.reddit.com//r/interestingasfuck/comments/1938bme/how_did_he_teach_them_to_not_follow_their_babies/;;294
Reddit;Is it insider trading if I bought Boeing puts while I am inside the wrecked airplane?;Kyrneh-1234;;2024/01/10;https://www.reddit.com//r/wallstreetbets/comments/1935frs/is_it_insider_trading_if_i_bought_boeing_puts/;Purely hypothetical of cause:  Imagine sitting in an airplane when suddenly the fucking door blows out.   Now, while everyone is screaming and grasping for air, you instead turn on your noise-cancelling head-phones to ignore that crying baby next to you, calmly open your robin-hood app (or whatever broker you prefer, idc), and load up on Boeing puts.   There is no way the market couldve already priced that in, it is literally just happening.  Would that be considered insider trading? I mean you are literally inside that wreck of an airplane...  On the other hand, one could argue that you are also outside the airplane, given that the door just blew off...  ;1387
Reddit;Amazon Lays Off ‚ÄòSeveral Hundred‚Äô Staffers at Prime Video and MGM;MarvelsGrantMan136;;2024/01/10;https://www.reddit.com//r/movies/comments/1938myj/amazon_lays_off_several_hundred_staffers_at_prime/;;1310
Reddit;Can I nap here?;Umer_-;;2024/01/10;https://www.reddit.com//r/Eyebleach/comments/193857p/can_i_nap_here/;;69
Reddit;me irl;SingleRecognition578;;2024/01/10;https://www.reddit.com//r/me_irl/comments/193aqud/me_irl/;;202
Reddit;to stand up for your own rights;29PiecesOfSilver;;2024/01/10;https://www.reddit.com//r/therewasanattempt/comments/193700l/to_stand_up_for_your_own_rights/;;1064
Reddit;A dose of reality;DemCast_USA;;2024/01/10;https://www.reddit.com//r/WorkReform/comments/193bff9/a_dose_of_reality/;;78
Reddit;The english got me;Augur-of-the-Deep;;2024/01/10;https://www.reddit.com//r/Damnthatsinteresting/comments/1936brn/the_english_got_me/;;710
Reddit;Cute waiting ü•∫ü•∫;nzhmar;;2024/01/10;https://www.reddit.com//r/cats/comments/1935oar/cute_waiting/;;331
Reddit;The MAGA Queen is not happy.;OutrageousMight457;;2024/01/10;https://www.reddit.com//r/PoliticalHumor/comments/1936ofm/the_maga_queen_is_not_happy/;;493
Reddit;My humble nomination for the worst scene of both series;goughow;;2024/01/10;https://www.reddit.com//r/TheLastAirbender/comments/19378l6/my_humble_nomination_for_the_worst_scene_of_both/;;647
Reddit;r/anime's Favorite Anime of 2023 Results;FetchFrosh;;2024/01/10;https://www.reddit.com//r/anime/comments/1938w2z/ranimes_favorite_anime_of_2023_results/;;1151
Reddit;Huh;diamondxxp;;2024/01/10;https://www.reddit.com//r/PeterExplainsTheJoke/comments/1938e1v/huh/;;132
Reddit;among the most frightful social events;prettyyxx;;2024/01/10;https://www.reddit.com//r/TikTokCringe/comments/193dni5/among_the_most_frightful_social_events/;;271
Reddit;üî• A Male Buck defend his does when a Ram starts harassing them until the Buck fights back üî•;EmronRazaqi69;;2024/01/10;https://www.reddit.com//r/NatureIsFuckingLit/comments/193c48d/a_male_buck_defend_his_does_when_a_ram_starts/;;301
Reddit;The similarities are uncanny.;EvaInTheUSA;;2024/01/10;https://www.reddit.com//r/BikiniBottomTwitter/comments/193a1ux/the_similarities_are_uncanny/;;82
Reddit;This man bout to be honey to a swarm of bees;Cleonce12;;2024/01/10;https://www.reddit.com//r/BlackPeopleTwitter/comments/193c2f5/this_man_bout_to_be_honey_to_a_swarm_of_bees/;;271
Reddit;"""I love money!""";rudra285;;2024/01/10;https://www.reddit.com//r/gaming/comments/1939iqq/i_love_money/;Less GaaS and Live Service please. Especially licensed games.;997
Reddit;This is the most wonderful woman-mother that ever existed;PrincessTastete;;2024/01/10;https://www.reddit.com//r/wholesomememes/comments/1936ul6/this_is_the_most_wonderful_womanmother_that_ever/;;126
Reddit;super adorable;MonkeyFlashys;;2024/01/10;https://www.reddit.com//r/Awww/comments/193b1bx/super_adorable/;;37
Reddit;Respect!;No_Description4363;;2024/01/10;https://www.reddit.com//r/meme/comments/1939pvb/respect/;;12
Reddit;Maybe maybe maybe;RefriDiet;;2024/01/10;https://www.reddit.com//r/maybemaybemaybe/comments/1935mda/maybe_maybe_maybe/;;740
Reddit;Hunter angered the GOP by surprisingly showing up at their hearing about holding him in contempt.;Lifegoesonforever;;2024/01/10;https://www.reddit.com//r/pics/comments/193f4rw/hunter_angered_the_gop_by_surprisingly_showing_up/;;599
Reddit;Oh she be dead...;Brilliant_Eagle9795;;2024/01/10;https://www.reddit.com//r/OSHA/comments/193ar7d/oh_she_be_dead/;;286
Reddit;Police officer just made my dayü§£ü§£ü§£ü§£;trekkerxxx;;2024/01/10;https://www.reddit.com//r/FunnyAnimals/comments/193at0d/police_officer_just_made_my_day/;;67
Reddit;good enough for Oxford;Diligent_Parsnip_250;;2024/01/10;https://www.reddit.com//r/marvelmemes/comments/193csk0/good_enough_for_oxford/;;99
Reddit;AITA for leaving my fiance because my body count does not align with his ‚Äútraditional values‚Äù?;FlowerSedative;;2024/01/10;https://www.reddit.com//r/AITAH/comments/1938d9e/aita_for_leaving_my_fiance_because_my_body_count/;!!!!UPDATE AT THE BOTTOM!!!!So let me get right into the story.I (21f) got engaged to my ex (24m) in late June of 2023. We met earlier that year and I thought that he was everything I‚Äôve ever wanted in a man. Living in the big city alone and working my a** off while going to Uni, I have met a few guys who I‚Äôve messed around with. To be exact, since my frist time i have slept with 5 more guys (including my fianc√©, so my body count was 6 all in all). When we first met he was the most amazing and loving guy I have ever met, we have talked through our relationships before each other and he didn‚Äôt seem to mind that much. I have to say that he is a really traditional Christian guy who lives on a farm, and I liked that about him, the peaceful life he was living. We talked about everything, kids, marriage etc. But after we have got engaged he started acting differently. His best friend and soon to be best man (19m) tried hooking up with me before I met my boyfriend. So I guess out of jealousy he started filling my boyfriend‚Äôs head with all kinds of things about my body count. For example: ‚ÄúMan, she has slept with one of the fboys I know and he only sleeps with hoes, but she is a nice girl idk what to think about her.‚ÄùAnd yes I met a guy who was exactly my type physically, and we hooked up, never seen or heard from him after that. After a few months later, my boyfriend started acting like he was entitled to my body. Even if I wasn‚Äôt ready or feeling like I wanted to be intimate he would bring out how I slept with ‚Äúbunch of guys‚Äù before him. Then he told me that he only slept with one girl before me.So we have had a lot of fights about that but I wanted to let that go and work on our relationship and marriage that was about to start. We talked and talked and whenever I did something that was not how he wanted it, he would bring up my body count. I got sick of that really, but the fights only started getting worse. He used to tell me that I would not be fit to be the mother of his children but in other moments he would dream about that and fantasize our life. His excuse for saying and insulting me was that his moral and religious beliefs don‚Äôt align with my past life and that sometimes he breaks out because of that. I tried to understand that, tried to work on my relationship with him and even pleaded for forgiveness. (Ik how stupid of me) But when I moved in with him and we had a fight about my body count AGAIN AND AGAIN, the least drop was his mother joining the argument. In exact words she said: ‚ÄúIf you were some mafia tattooed guy she would be more respectful of you. The next girl you bring home will first go through your sister‚Äôs and my own hands.‚Äù Meaning they would test her if she is a proper wife. That was when I‚Äôve had enough of that bull****. I called my mom and stepdad to pick me up (it was 1am) and they drove for 4 hours to get me home. Him and his mom apologized to me, begged me to come back. But after some of the talks  with my mom I realized that things were never going to change, even though I loved that guy and was willing to do everything to make the relationship work.After a month he reached out to me tried to mend our relationship, saying that if I really loved him I would come back and he promised to never speak of my previous relationships ever again. Well you know from the title that I didn‚Äôt go back to him, but AITA for leaving him?UPDATE:So I saw some of the people who thought that I cheated on my ex or that I made this story up so let me tell you a little bit more about it.I DID NOT CHEAT ON HIM! The guy that I had a one night stand (we have been messaging for months before that happened) with was like a year before we got into the relatioship. The best friend of my ex knew the guy that is why my ex and him talked about that. THIS IS NOT A FAKE STORY! It took me two months to get this off my chest and talk about it, I have lost friends because of this guy who I‚Äôm reconnecting with rn. I am thankful to those who are supportive of me irl as much as I am to those on this platform. I was just going for a walk with my friend N (25m) who knows my ex and he was shocked when I told him the reason. We are not from the US, we are Balkan so posting screenshots won‚Äôt mean much cause majority would not understand the native language. HIS MOM CALLED MY MOM!Yes a week ago his toxic mom called mine apologizing and begging her to let me come back to be their daughter in law. Ofc my mom politely denied her offer and blocked her number. The reason why she wanted me back is because ‚ÄúNO ONE EVER LOVED HIS SON AS MUCH AS ME AND I HAVE MANY TALENTS I COULD PASS DOWN ON HER GRANDCHILDREN‚Äù Hell no! I BLOCKED HIM AND HIS BEST FRIEND!!;2439
Reddit;Well done;sweetiiezc;;2024/01/10;https://www.reddit.com//r/holdmycatnip/comments/193bgmz/well_done/;;55
Reddit;Oh shit;dr-c0990;;2024/01/10;https://www.reddit.com//r/formuladank/comments/193ccbz/oh_shit/;;189
Reddit;whiteLies;Jubs300;;2024/01/10;https://www.reddit.com//r/ProgrammerHumor/comments/193doct/whitelies/;;54
Reddit;Hol up hol up;PresentationNo712;;2024/01/10;https://www.reddit.com//r/HolUp/comments/1937lw0/hol_up_hol_up/;;31
Reddit;Cursed_Bully: ur gay;WhimsyWanda;;2024/01/10;https://www.reddit.com//r/cursedcomments/comments/193awqs/cursed_bully_ur_gay/;;40
Reddit;Wealthy people literally eating the polar ice caps;Pastel_Lich;;2024/01/10;https://www.reddit.com//r/LateStageCapitalism/comments/1938qco/wealthy_people_literally_eating_the_polar_ice_caps/;;184
Reddit;Texans 'fear' of repeat of 2021 ahead of cold front, freeze;audiomuse1;;2024/01/10;https://www.reddit.com//r/LeopardsAteMyFace/comments/193d20i/texans_fear_of_repeat_of_2021_ahead_of_cold_front/;;387
Reddit;This Copy of Animal Farm in my class‚Ä¶;Scared-Ad-1956;;2024/01/10;https://www.reddit.com//r/gravityfalls/comments/193b8yf/this_copy_of_animal_farm_in_my_class/;;55
Reddit;‚ÄòQanon Shaman‚Äô Demands The FBI Return The Iconic Horns He Wore During Riot;gootyy;;2024/01/10;https://www.reddit.com//r/nottheonion/comments/1935a2b/qanon_shaman_demands_the_fbi_return_the_iconic/;;859
Reddit;The naked man fears no pickpocket;GotHotNot;;2024/01/10;https://www.reddit.com//r/technicallythetruth/comments/193762y/the_naked_man_fears_no_pickpocket/;;95
Reddit;I spent two months making this. Am I stupid? ;IntoxicateTCP;;2024/01/10;https://www.reddit.com//r/nbacirclejerk/comments/193amqp/i_spent_two_months_making_this_am_i_stupid/;;149
Reddit;Noted Christian scholar urges evangelicals to abandon their church as 'It has lost its religious and moral credibility and is a source of more harm than good.';Leeming;;2024/01/10;https://www.reddit.com//r/atheism/comments/193akac/noted_christian_scholar_urges_evangelicals_to/;;140
Reddit;I dont know wether it's old news, but the DC-15's front is an unmodified, upside down E-11;K3psu;;2024/01/10;https://www.reddit.com//r/StarWars/comments/193b95a/i_dont_know_wether_its_old_news_but_the_dc15s/;;102
Reddit;Mammatus clouds in Argentina;Umer_-;;2024/01/10;https://www.reddit.com//r/oddlysatisfying/comments/1936a4o/mammatus_clouds_in_argentina/;;74
Reddit;Colorized video from 1906, where English children encounter a camera for the first time;oklolzzzzs;;2024/01/10;https://www.reddit.com//r/OldSchoolCool/comments/193972z/colorized_video_from_1906_where_english_children/;;343
Reddit;Approximately 3 minutes ago i swallowed some glowstick fluid while doing math homework;LorenzoIsASimp;;2024/01/10;https://www.reddit.com//r/notinteresting/comments/1939x70/approximately_3_minutes_ago_i_swallowed_some/;;332
Reddit;Nothing quite like trolling the traitors;Historical-Echo-7760;;2024/01/10;https://www.reddit.com//r/ShermanPosting/comments/19371n8/nothing_quite_like_trolling_the_traitors/;;83
Reddit;[COMIC] The best Hydro;smol_schrodinger_cat;;2024/01/10;https://www.reddit.com//r/Genshin_Impact/comments/193c6uh/comic_the_best_hydro/;;50
Reddit;"""Land of the workers with no benefits""";OfficialPsoster;;2024/01/10;https://www.reddit.com//r/facepalm/comments/1937cbq/land_of_the_workers_with_no_benefits/;;3177
Reddit;Choose wisely;wcslater;;2024/01/10;https://www.reddit.com//r/mathmemes/comments/193686c/choose_wisely/;;421
Reddit;10mins of the most intense pleasure possible does not outweigh 10mins of the most intense pain possible.;percavil3;;2024/01/10;https://www.reddit.com//r/Showerthoughts/comments/193bo6j/10mins_of_the_most_intense_pleasure_possible_does/;"You would not take 10mins of pure torture for 10mins of pure pleasure/bliss. Maximum pain overshadows maximum pleasure&#x200B;Edit: talking about a 1:1 duration ratio, of the maximum feeling on each end of the spectrum. Most people would tap out after 1 minute of maximum torture, if it was an option.&#x200B;";322
Reddit;It's funny because it's true ü´•;unfunnyFucker;;2024/01/10;https://www.reddit.com//r/memes/comments/1937hmc/its_funny_because_its_true/;;86
Reddit;"[Charania] Sources: Netflix is creating a new NBA documentary series modeled after its NFL ""Quarterback"" show. The five players chosen for first season of the project: LeBron James, Jayson Tatum, Jimmy Butler, Anthony Edwards and Domantas Sabonis.";MarvelsGrantMan136;;2024/01/10;https://www.reddit.com//r/nba/comments/193bwj9/charania_sources_netflix_is_creating_a_new_nba/;;453
Reddit;Can't believe I lost 500k like this;Broad-Support2998;;2024/01/10;https://www.reddit.com//r/gtaonline/comments/1935moh/cant_believe_i_lost_500k_like_this/;Wtff;369
Reddit;Talkative parents a key factor in children‚Äôs language development: study finds that socioeconomic status and gender don't play roles in language development, but the amount of adult talk does;giuliomagnifico;;2024/01/10;https://www.reddit.com//r/science/comments/1939r84/talkative_parents_a_key_factor_in_childrens/;;98
Reddit;ichüöúiel;Pory02;;2024/01/10;https://www.reddit.com//r/ich_iel/comments/19370hj/ichiel/;;374
Reddit;The end... ;MaxMustemal;;2024/01/10;https://www.reddit.com//r/ContagiousLaughter/comments/193clne/the_end/;;87
Reddit;Annoying Intelligence;maglag40k;;2024/01/10;https://www.reddit.com//r/Grimdank/comments/1939mbt/annoying_intelligence/;;256
Reddit;GPUs then and now;WhisperingWispxxx;;2024/01/10;https://www.reddit.com//r/pcmasterrace/comments/1933sz8/gpus_then_and_now/;;2072
Reddit;Taylor Swift‚Äôs ‚ÄúIvy‚Äù Reveals the Release Date and Content of the Elden Ring DLC;Jiatao24;;2024/01/10;https://www.reddit.com//r/Eldenring/comments/193agvx/taylor_swifts_ivy_reveals_the_release_date_and/;After hours of detailed analysis, I have concluded that [‚ÄúIvy‚Äù by Taylor Swift](https://youtu.be/9nIOx-ezlzA?si=-L2mUKcBvRfMV46I) is a song of lament from Ranni towards her previous tarnished lover, Vyke. In typical Taylor Swift fashion, it contains clues that allow us to conclusively determine the release date of the Shadows of the Erdtree DLC.We‚Äôre going start with the first verse:*How's one to know?**I'd meet you where the spirit meets the bones**In a faith forgotten land**In from the snow**Your touch brought forth an incandescent glow**Tarnished but so grand*In these lines, Swift name-drops the word ‚Äútarnished,‚Äù and also clearly references the Guidance of Grace as the ‚Äúincandescent glow‚Äù when you touch the site of grace in the Church of Elleh, where you meet Ranni for the first time (as Renna). Interestingly, the [description of the Church of Elleh](https://eldenring.wiki.fextralife.com/Church+of+Elleh) in the wiki states that there are ‚Äúweeds are overtaking the walls‚Äù and in game, and there is clearly ivy draped upon the walls of the Church.The Guidance of Grace points the tarnished towards the next goal in the game, and as such, Swift gives an indication that we Tarnished should pay attention. This is a bit of a little bit of a non-diegetic reason for the inclusion of this lyric, but Swift is no stranger to including non-diegetic portions in her songs.*And the old widow goes to the stone every day**But I don't, I just sit here and wait**Grieving for the living*This seems to be a reference to Ranni‚Äôs mother Rennala and the golden stone she carries with her after her husband Radagon leaves her. The ‚Äúliving‚Äù she grieves for could be Godwyn the Golden, who is alive but dead in spirit, causing the Shattering of the Elden Ring. Alternatively, she could be grieving for her own dead body. After all, now she only has this doll body, which doesn‚Äôt do anything other than sitting and waiting.*\[Chorus\]**Oh, goddamn**My pain fits in the palm of your freezing hand**Taking mine, but it's been promised to another**Oh, I can't**Stop you putting roots in my dreamland**My house of stone, your ivy grows**And now I'm covered in you*The ‚Äúfreezing hand‚Äù is the second piece of information on the subject of this song. You encounter Vyke in an evergaol in the Mountaintop of the Giants, which is consistent with the freezing hands mentioned in the song.The other reference in the chorus is the ‚Äúroots in my dreamland,‚Äù a clear reference to the Deeproot Depths, the location of Fia‚Äôs dream, underneath the literal roots of the Erdtree. Because of the proximity of the Three Fingers & the Frenzied Flame Proscription and the Deeproot Depths (there‚Äôs a passageway connecting them!), I interpret this as metonymy connecting the two locations as one. And of course, we know that Vyke must have traversed this route in the past because of his current state having partially embraced the Frenzied Flame.*I wish to know**The fatal flaw that makes you long to be**Magnificently cursed**He's in the room**Your opal eyes are all I wish to see**He wants what's only yours*The ‚Äúfatal flaw‚Äù here is Vyke‚Äôs refusal to set his maiden on fire at the Mountaintops of the Giants, which leads him to the ‚Äú\[magnificent\] curse‚Äù of the Frenzied Flame. In other words, it is his love for his maiden, which is of course Ranni‚Äôs wish for Vyke‚Äôs love. After all, in game, if you take up the Frenzied Flame, you spurn Ranni‚Äôs hand and make the Age of Stars impossible. Ranni is expressing her regret at not being able to take Vyke‚Äôs hand.Additionally, Vyke‚Äôs eyes are a [milky shade of blue](https://www.youtube.com/watch?v=An_YVMvC7C4&t=168s), which is a common hue found in opals. Opals are also commonly cited as having [an inner fire](https://www.reddit.com/r/TaylorSwift/comments/zfbbz5/lyric_analysis_opal_eyes_does_not_in_fact_refer/), which is exactly the result of embracing the Frenzied Flame.*Clover blooms in the fields**Spring breaks loose, the time is near**What would he do if he found us out?**Crescent moon, coast is clear**Spring breaks loose, but so does fear**He's gonna burn this house to the ground**How's one to know?**I'd live and die for moments that we stole**On begged and borrowed time**So tell me to run**Or dare to sit and watch what we'll become**And drink my husband's wine*The interpretation of these lines eluded me for the longest time, as I could not place this line within the romance between Ranni and Vyke. There are clear references to the crescent moon, a symbol of Lunar Princess Ranni, and the Frenzied Flame, but nothing that would construct a full narrative.However, the fields blooming is somewhat reminiscent of the image teaser for Shadow of the Erdtree. This, combined with the apprehension and ‚Äúfinding out‚Äù in these lines, led me to wonder if this is the answer to the current biggest question in Elden Ring: ‚ÄúWhen is Shadows of the Erdtree releasing?‚Äù This next line, ‚Äú\[s\]pring breaks loose, the time is near '' indicates that this is happening close after the start of spring, which is typically marked by the vernal equinox (which will be March 19th). The ‚Äúcrescent moon‚Äù clues us into being somewhere between April 3rd to April 15th, with exceptions on April 8th and 9th, during which the moon is not visible (new moon).Additionally, this is further corroborated with my sudden realization that the title, Ivy - or IV - is the Roman numeral for 4. This without any conceivable doubt indicates both that the release will be in the 4th month (April), and it is a 202**4** release.Of these 11 possible days, at this point, we veer firmly into my inexhaustible Swiftie lore, as it is common knowledge that Taylor Swift‚Äôs favorite number is 13. As such, it is obvious to me that Shadows of the Erdtree will release on April 13, 2024 and will explore Vyke‚Äôs story more thoroughly through Ranni‚Äôs previous relationship.;198
Reddit;That escalated quickly ;maneshwarS;;2024/01/10;https://www.reddit.com//r/yesyesyesyesno/comments/1937kdu/that_escalated_quickly/;;336
Reddit;Meirl;Whyayankhan;;2024/01/10;https://www.reddit.com//r/meirl/comments/193an8g/meirl/;;12
Reddit;Vultures will be released on Friday at 2:43. Look at Kanye's eyes;firefly8777;;2024/01/10;https://www.reddit.com//r/Kanye/comments/193bsqb/vultures_will_be_released_on_friday_at_243_look/;;115
Reddit;Friend sells $200 shoes I left in his trunk;Sui_2;;2024/01/10;https://www.reddit.com//r/mildlyinfuriating/comments/193ddzg/friend_sells_200_shoes_i_left_in_his_trunk/;;417
Reddit;the 10/10 ones look so delicious üò≥;Plus_Bodybuilder_168;;2024/01/10;https://www.reddit.com//r/Satisfyingasfuck/comments/193c5f4/the_1010_ones_look_so_delicious/;;62
Reddit;Every two days with you people;Not_A_Mindflayer;;2024/01/10;https://www.reddit.com//r/wizardposting/comments/1939qjd/every_two_days_with_you_people/;;116
Reddit;Subaru‚Äôs recruitment in a nutshell;Panzerkrabbe;;2024/01/10;https://www.reddit.com//r/Hololive/comments/1939a7f/subarus_recruitment_in_a_nutshell/;;141
Reddit;A cool guide to how many animals are killed every day on a global scale;PaperFantastic7672;;2024/01/10;https://www.reddit.com//r/coolguides/comments/193c7rq/a_cool_guide_to_how_many_animals_are_killed_every/;;601
Reddit;guess ill never have blade :|;SykoManiax;;2024/01/10;https://www.reddit.com//r/HonkaiStarRail/comments/193c8tu/guess_ill_never_have_blade/;;104
Reddit;They‚Äôre called Graboids;Smartastic;;2024/01/10;https://www.reddit.com//r/JeffArcuri/comments/193aelv/theyre_called_graboids/;;94
Reddit;He still loves him ü•≤;EpicSansMemeXd;;2024/01/10;https://www.reddit.com//r/Deltarune/comments/1936rsz/he_still_loves_him/;;114
Reddit;The end of an era. You will be missed. Thank you for everything!;Tiger_Torme;;2024/01/10;https://www.reddit.com//r/fivenightsatfreddys/comments/193a7mn/the_end_of_an_era_you_will_be_missed_thank_you/;;75
Reddit;Starting the day off right with my limited edition Stanley.;grandpa-was-a-Nazi;;2024/01/10;https://www.reddit.com//r/HydroHomies/comments/1938z0f/starting_the_day_off_right_with_my_limited/;;104
Reddit;Choose your character;BabyBecky-;;2024/01/10;https://www.reddit.com//r/IllegallySmolCats/comments/1936v9q/choose_your_character/;;108
Reddit;THE GAME THEORY IS REAL;Sussy_Baka_1923;;2024/01/10;https://www.reddit.com//r/NonPoliticalTwitter/comments/193cu0k/the_game_theory_is_real/;;36
Reddit;Capcom is adding DRM Enigma Protector to their back catalog of games. Prevents modding, cheat engine, and reduces performance by up to 10-15 fps with stutters.;Mikasa_Tsukasa;;2024/01/10;https://www.reddit.com//r/pcgaming/comments/193800v/capcom_is_adding_drm_enigma_protector_to_their/;;595
Reddit;Hunter Biden makes surprise appearance at contempt of Congress hearing;-Art--;;2024/01/10;https://www.reddit.com//r/politics/comments/193b2zg/hunter_biden_makes_surprise_appearance_at/;;801
Reddit;He got tangled in his own parachute;LettersAndNumbers340;;2024/01/10;https://www.reddit.com//r/nextfuckinglevel/comments/1939g9n/he_got_tangled_in_his_own_parachute/;;176
Reddit;Right into my trap;RegularNoodles;;2024/01/10;https://www.reddit.com//r/dankmemes/comments/193a0rf/right_into_my_trap/;;23
Reddit;Guys, why the piston on the bottom right doesn't work?;Shakaow15;;2024/01/10;https://www.reddit.com//r/MinecraftMemes/comments/193alhf/guys_why_the_piston_on_the_bottom_right_doesnt/;;163
Arxiv;Hierarchical Dirichlet Process and Relative Entropy;Shui Feng;;2022/10/24;http://arxiv.org/abs/2210.13142v1;The Hierarchical Dirichlet process is a discrete random measure serving as animportant prior in Bayesian non-parametrics. It is motivated with the study ofgroups of clustered data. Each group is modelled through a level two Dirichletprocess and all groups share the same base distribution which itself is a drawnfrom a level one Dirichlet process. It has two concentration parameters withone at each level. The main results of the paper are the law of large numbersand large deviations for the hierarchical Dirichlet process and its mass whenboth concentration parameters converge to infinity. The large deviation ratefunctions are identified explicitly. The rate function for the hierarchicalDirichlet process consists of two terms corresponding to the relative entropiesat each level. It is less than the rate function for the Dirichlet process,which reflects the fact that the number of clusters under the hierarchicalDirichlet process has a slower growth rate than under the Dirichlet process.;
Arxiv;Spectral analysis of communication networks using Dirichlet eigenvalues;Alexander Tsiatas;Iraj Saniee,Onuttom Narayan,Matthew Andrews;2011/02/17;http://arxiv.org/abs/1102.3722v2;"The spectral gap of the graph Laplacian with Dirichlet boundary conditions iscomputed for the graphs of several communication networks at the IP-layer,which are subgraphs of the much larger global IP-layer network. We show thatthe Dirichlet spectral gap of these networks is substantially larger than thestandard spectral gap and is likely to remain non-zero in the infinite graphlimit. We first prove this result for finite regular trees, and show that theDirichlet spectral gap in the infinite tree limit converges to the spectral gapof the infinite tree. We also perform Dirichlet spectral clustering on theIP-layer networks and show that it often yields cuts near the network core thatcreate genuine single-component clusters. This is much better than traditionalspectral clustering where several disjoint fragments near the periphery areliable to be misleadingly classified as a single cluster. Spectral clusteringis often used to identify bottlenecks or congestion; since congestion in thesenetworks is known to peak at the core, our results suggest that Dirichletspectral clustering may be better at finding bona-fide bottlenecks.";
Arxiv;Dirichlet Process Mixtures of Generalized Mallows Models;Marina Meila;Harr Chen;2012/03/15;http://arxiv.org/abs/1203.3496v1;We present a Dirichlet process mixture model over discrete incompleterankings and study two Gibbs sampling inference techniques for estimatingposterior clusterings. The first approach uses a slice sampling subcomponentfor estimating cluster parameters. The second approach marginalizes out severalcluster parameters by taking advantage of approximations to the conditionalposteriors. We empirically demonstrate (1) the effectiveness of thisapproximation for improving convergence, (2) the benefits of the Dirichletprocess model over alternative clustering techniques for ranked data, and (3)the applicability of the approach to exploring large realworld rankingdatasets.;
Arxiv;Clustering consistency with Dirichlet process mixtures;Filippo Ascolani;Antonio Lijoi,Giovanni Rebaudo,Giacomo Zanella;2022/05/25;http://arxiv.org/abs/2205.12924v1;Dirichlet process mixtures are flexible non-parametric models, particularlysuited to density estimation and probabilistic clustering. In this work westudy the posterior distribution induced by Dirichlet process mixtures as thesample size increases, and more specifically focus on consistency for theunknown number of clusters when the observed data are generated from a finitemixture. Crucially, we consider the situation where a prior is placed on theconcentration parameter of the underlying Dirichlet process. Previous findingsin the literature suggest that Dirichlet process mixtures are typically notconsistent for the number of clusters if the concentration parameter is heldfixed and data come from a finite mixture. Here we show that consistency forthe number of clusters can be achieved if the concentration parameter isadapted in a fully Bayesian way, as commonly done in practice. Our results arederived for data coming from a class of finite mixtures, with mild assumptionson the prior for the concentration parameter and for a variety of choices oflikelihood kernels for the mixture.;
Arxiv;A Hierarchical Dirichlet Process Model with Multiple Levels of  Clustering for Human EEG Seizure Modeling;Drausin Wulsin;Shane Jensen,Brian Litt;2012/06/18;http://arxiv.org/abs/1206.4616v1;Driven by the multi-level structure of human intracranialelectroencephalogram (iEEG) recordings of epileptic seizures, we introduce anew variant of a hierarchical Dirichlet Process---the multi-level clusteringhierarchical Dirichlet Process (MLC-HDP)---that simultaneously clustersdatasets on multiple levels. Our seizure dataset contains brain activityrecorded in typically more than a hundred individual channels for each seizureof each patient. The MLC-HDP model clusters over channels-types, seizure-types,and patient-types simultaneously. We describe this model and its implementationin detail. We also present the results of a simulation study comparing theMLC-HDP to a similar model, the Nested Dirichlet Process and finallydemonstrate the MLC-HDP's use in modeling seizures across multiple patients. Wefind the MLC-HDP's clustering to be comparable to independent human physicianclusterings. To our knowledge, the MLC-HDP model is the first in the epilepsyliterature capable of clustering seizures within and between patients.;
Arxiv;The supervised hierarchical Dirichlet process;Andrew M. Dai;Amos J. Storkey;2014/12/17;http://arxiv.org/abs/1412.5236v1;"We propose the supervised hierarchical Dirichlet process (sHDP), anonparametric generative model for the joint distribution of a group ofobservations and a response variable directly associated with that whole group.We compare the sHDP with another leading method for regression on grouped data,the supervised latent Dirichlet allocation (sLDA) model. We evaluate our methodon two real-world classification problems and two real-world regressionproblems. Bayesian nonparametric regression models based on the Dirichletprocess, such as the Dirichlet process-generalised linear models (DP-GLM) havepreviously been explored; these models allow flexibility in modelling nonlinearrelationships. However, until now, Hierarchical Dirichlet Process (HDP)mixtures have not seen significant use in supervised problems with grouped datasince a straightforward application of the HDP on the grouped data results inlearnt clusters that are not predictive of the responses. The sHDP solves thisproblem by allowing for clusters to be learnt jointly from the group structureand from the label assigned to each group.";
Arxiv;Scalable Inference for Latent Dirichlet Allocation;James Petterson;Tiberio Caetano;2009/09/25;http://arxiv.org/abs/0909.4603v1;We investigate the problem of learning a topic model - the well-known LatentDirichlet Allocation - in a distributed manner, using a cluster of C processorsand dividing the corpus to be learned equally among them. We propose a simpleapproximated method that can be tuned, trading speed for accuracy according tothe task at hand. Our approach is asynchronous, and therefore suitable forclusters of heterogenous machines.;
Arxiv;Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process  Mixture;Trevor Campbell;Miao Liu,Brian Kulis,Jonathan P. How,Lawrence Carin;2013/05/28;http://arxiv.org/abs/1305.6659v2;This paper presents a novel algorithm, based upon the dependent Dirichletprocess mixture model (DDPMM), for clustering batch-sequential data containingan unknown number of evolving clusters. The algorithm is derived via alow-variance asymptotic analysis of the Gibbs sampling algorithm for the DDPMM,and provides a hard clustering with convergence guarantees similar to those ofthe k-means algorithm. Empirical results from a synthetic test with movingGaussian clusters and a test with real ADS-B aircraft trajectory datademonstrate that the algorithm requires orders of magnitude less computationaltime than contemporary probabilistic and hard clustering algorithms, whileproviding higher accuracy on the examined datasets.;
Arxiv;Dirichlet-tree multinomial mixtures for clustering microbiome  compositions;Jialiang Mao;Li Ma;2020/08/02;http://arxiv.org/abs/2008.00400v2;Studying the human microbiome has gained substantial interest in recentyears, and a common task in the analysis of these data is to cluster microbiomecompositions into subtypes. This subdivision of samples into subgroups servesas an intermediary step in achieving personalized diagnosis and treatment. Inapplying existing clustering methods to modern microbiome studies including theAmerican Gut Project (AGP) data, we found that this seemingly standard task,however, is very challenging in the microbiome composition context due toseveral key features of such data. Standard distance-based clusteringalgorithms generally do not produce reliable results as they do not take intoaccount the heterogeneity of the cross-sample variability among the bacterialtaxa, while existing model-based approaches do not allow sufficient flexibilityfor the identification of complex within-cluster variation from cross-clustervariation. Direct applications of such methods generally lead to overlydispersed clusters in the AGP data and such phenomenon is common for othermicrobiome data. To overcome these challenges, we introduce Dirichlet-treemultinomial mixtures (DTMM) as a Bayesian generative model for clusteringamplicon sequencing data in microbiome studies. DTMM models the microbiomepopulation with a mixture of Dirichlet-tree kernels that utilizes thephylogenetic tree to offer a more flexible covariance structure incharacterizing within-cluster variation, and it provides a means foridentifying a subset of signature taxa that distinguish the clusters. Weperform extensive simulation studies to evaluate the performance of DTMM andcompare it to state-of-the-art model-based and distance-based clusteringmethods in the microbiome context. Finally, we report a case study on the fecaldata from the AGP to identify compositional clusters among individuals withinflammatory bowel disease and diabetes.;
Arxiv;Percolation Perturbations in Potential Theory and Random Walks;Itai Benjamini;Russell Lyons,Oded Schramm;1998/04/02;http://arxiv.org/abs/math/9804010v1;We show that on a Cayley graph of a nonamenable group, almost surely theinfinite clusters of Bernoulli percolation are transient for simple randomwalk, that simple random walk on these clusters has positive speed, and thatthese clusters admit bounded harmonic functions. A principal new finding onwhich these results are based is that such clusters admit invariant randomsubgraphs with positive isoperimetric constant.  We also show that percolation clusters in any amenable Cayley graph almostsurely admit no nonconstant harmonic Dirichlet functions. Conversely, on aCayley graph admitting nonconstant harmonic Dirichlet functions, almost surelythe infinite clusters of $p$-Bernoulli percolation also have nonconstantharmonic Dirichlet functions when $p$ is sufficiently close to 1. Manyconjectures and questions are presented.;
Arxiv;Informed Bayesian Finite Mixture Models via Asymmetric Dirichlet Priors;Garritt L. Page;Massimo Ventrucci,Maria Franco-Villoria;2023/08/01;http://arxiv.org/abs/2308.00768v1;Finite mixture models are flexible methods that are commonly used formodel-based clustering. A recent focus in the model-based clustering literatureis to highlight the difference between the number of components in a mixturemodel and the number of clusters. The number of clusters is more relevant froma practical stand point, but to date, the focus of prior distributionformulation has been on the number of components. In light of this, we developa finite mixture methodology that permits eliciting prior information directlyon the number of clusters in an intuitive way. This is done by employing anasymmetric Dirichlet distribution as a prior on the weights of a finitemixture. Further, a penalized complexity motivated prior is employed for theDirichlet shape parameter. We illustrate the ease to which prior informationcan be elicited via our construction and the flexibility of the resultinginduced prior on the number of clusters. We also demonstrate the utility of ourapproach using numerical experiments and two real world data sets.;
Arxiv;Numerical conformal mapping with rational functions;Lloyd N. Trefethen;;2019/11/09;http://arxiv.org/abs/1911.03696v1;"New algorithms are presented for numerical conformal mapping based onrational approximations and the solution of Dirichlet problems by least-squaresfitting on the boundary. The methods are targeted at regions with corners,where the Dirichlet problem is solved by the ""lightning Laplace solver"" withpoles exponentially clustered near each singularity. For polygons and circularpolygons, further simplifications are possible.";
Arxiv;Revisiting k-means: New Algorithms via Bayesian Nonparametrics;Brian Kulis;Michael I. Jordan;2011/11/02;http://arxiv.org/abs/1111.0352v2;Bayesian models offer great flexibility for clusteringapplications---Bayesian nonparametrics can be used for modeling infinitemixtures, and hierarchical Bayesian models can be utilized for sharing clustersacross multiple data sets. For the most part, such flexibility is lacking inclassical clustering methods such as k-means. In this paper, we revisit thek-means clustering algorithm from a Bayesian nonparametric viewpoint. Inspiredby the asymptotic connection between k-means and mixtures of Gaussians, we showthat a Gibbs sampling algorithm for the Dirichlet process mixture approaches ahard clustering algorithm in the limit, and further that the resultingalgorithm monotonically minimizes an elegant underlying k-means-like clusteringobjective that includes a penalty for the number of clusters. We generalizethis analysis to the case of clustering multiple data sets through a similarasymptotic argument with the hierarchical Dirichlet process. We also discussfurther extensions that highlight the benefits of our analysis: i) a spectralrelaxation involving thresholded eigenvectors, and ii) a normalized cut graphclustering algorithm that does not fix the number of clusters in the graph.;
Arxiv;Bayesian Clustering of Transcription Factor Binding Motifs;Shane T. Jensen;Jun S. Liu;2006/10/22;http://arxiv.org/abs/math/0610655v1;Genes are often regulated in living cells by proteins called transcriptionfactors (TFs) that bind directly to short segments of DNA in close proximity tospecific genes. These binding sites have a conserved nucleotide appearance,which is called a motif. Several recent studies of transcriptional regulationrequire the reduction of a large collection of motifs into clusters based onthe similarity of their nucleotide composition. We present a principledapproach to this clustering problem based upon a Bayesian hierarchical modelthat accounts for both within- and between-motif variability. We use aDirichlet process prior distribution that allows the number of clusters to varyand we also present a novel generalization that allows the core width of eachmotif to vary. This clustering model is implemented, using a Gibbs samplingstrategy, on several collections of transcription factor motif matrices. Ourclusters provide a means by which to organize transcription factors based onbinding motif similarities, which can be used to reduce motif redundancy withinlarge databases such as JASPAR and TRANSFAC. Finally, our clustering procedurehas been used in combination with discovery of evolutionarily-conserved motifsto predict co-regulated genes. An alternative to our Dirichlet process priordistribution is explored but shows no substantive difference in the clusteringresults for our datasets. Our Bayesian clustering model based on the Dirichletprocess has several advantages over traditional clustering methods that couldmake our procedure appropriate and useful for many clustering applications.;
Arxiv;DIMM-SC: A Dirichlet mixture model for clustering droplet-based single  cell transcriptomic data;Zhe Sun;Ting Wang,Ke Deng,Xiao-Feng Wang,Robert Lafyatis,Ying Ding,Ming Hu,Wei Chen;2017/04/06;http://arxiv.org/abs/1704.02007v1;Motivation: Single cell transcriptome sequencing (scRNA-Seq) has become arevolutionary tool to study cellular and molecular processes at single cellresolution. Among existing technologies, the recently developed droplet-basedplatform enables efficient parallel processing of thousands of single cellswith direct counting of transcript copies using Unique Molecular Identifier(UMI). Despite the technology advances, statistical methods and computationaltools are still lacking for analyzing droplet-based scRNA-Seq data.Particularly, model-based approaches for clustering large-scale single celltranscriptomic data are still under-explored. Methods: We developed DIMM-SC, aDirichlet Mixture Model for clustering droplet-based Single Cell transcriptomicdata. This approach explicitly models UMI count data from scRNA-Seq experimentsand characterizes variations across different cell clusters via a Dirichletmixture prior. An expectation-maximization algorithm is used for parameterinference. Results: We performed comprehensive simulations to evaluate DIMM-SCand compared it with existing clustering methods such as K-means, CellTree andSeurat. In addition, we analyzed public scRNA-Seq datasets with known clusterlabels and in-house scRNA-Seq datasets from a study of systemic sclerosis withprior biological knowledge to benchmark and validate DIMM-SC. Both simulationstudies and real data applications demonstrated that overall, DIMM-SC achievessubstantially improved clustering accuracy and much lower clusteringvariability compared to other existing clustering methods. More importantly, asa model-based approach, DIMM-SC is able to quantify the clustering uncertaintyfor each single cell, facilitating rigorous statistical inference andbiological interpretations, which are typically unavailable from existingclustering methods.;
Arxiv;Graphical Dirichlet Process for Clustering Non-Exchangeable Grouped Data;Arhit Chakrabarti;Yang Ni,Ellen Ruth A. Morris,Michael L. Salinas,Robert S. Chapkin,Bani K. Mallick;2023/02/17;http://arxiv.org/abs/2302.09111v2;We consider the problem of clustering grouped data with possiblynon-exchangeable groups whose dependencies can be characterized by a knowndirected acyclic graph. To allow the sharing of clusters among thenon-exchangeable groups, we propose a Bayesian nonparametric approach, termedgraphical Dirichlet process, that jointly models the dependent group-specificrandom measures by assuming each random measure to be distributed as aDirichlet process whose concentration parameter and base probability measuredepend on those of its parent groups. The resulting joint stochastic processrespects the Markov property of the directed acyclic graph that links thegroups. We characterize the graphical Dirichlet process using a novelhypergraph representation as well as the stick-breaking representation, therestaurant-type representation, and the representation as a limit of a finitemixture model. We develop an efficient posterior inference algorithm andillustrate our model with simulations and a real grouped single-cell dataset.;
Arxiv;Consistency Analysis for the Doubly Stochastic Dirichlet Process;Xing Sun;Nelson H. C. Yung,Edmund Y. Lam,Hayden K. -H. So;2016/05/24;http://arxiv.org/abs/1605.07358v1;"This technical report proves components consistency for the Doubly StochasticDirichlet Process with exponential convergence of posterior probability. Wealso present the fundamental properties for DSDP as well as inferencealgorithms. Simulation toy experiment and real-world experiment results forsingle and multi-cluster also support the consistency proof. This report isalso a support document for the paper ""Computationally Efficient HyperspectralData Learning Based on the Doubly Stochastic Dirichlet Process"".";
Arxiv;"Powered Dirichlet Process for Controlling the Importance of  ""Rich-Get-Richer"" Prior Assumptions in Bayesian Clustering";Ga√´l Poux-M√©dard;Julien Velcin,Sabine Loudcher;2021/04/26;http://arxiv.org/abs/2104.12485v1;"One of the most used priors in Bayesian clustering is the Dirichlet prior. Itcan be expressed as a Chinese Restaurant Process. This process allowsnonparametric estimation of the number of clusters when partitioning datasets.Its key feature is the ""rich-get-richer"" property, which assumes a cluster hasan a priori probability to get chosen linearly dependent on population. In thispaper, we show that such prior is not always the best choice to model data. Wederive the Powered Chinese Restaurant process from a modified version of theDirichlet-Multinomial distribution to answer this problem. We then develop someof its fundamental properties (expected number of clusters, convergence).Unlike state-of-the-art efforts in this direction, this new formulation allowsfor direct control of the importance of the ""rich-get-richer"" prior.";
Arxiv;Flexible clustering via hidden hierarchical Dirichlet priors;Antonio Lijoi;Igor Pr√ºnster,Giovanni Rebaudo;2022/01/18;http://arxiv.org/abs/2201.06994v1;The Bayesian approach to inference stands out for naturally allowingborrowing information across heterogeneous populations, with different samplespossibly sharing the same distribution. A popular Bayesian nonparametric modelfor clustering probability distributions is the nested Dirichlet process, whichhowever has the drawback of grouping distributions in a single cluster whenties are observed across samples. With the goal of achieving a flexible andeffective clustering method for both samples and observations, we investigate anonparametric prior that arises as the composition of two different discreterandom structures and derive a closed-form expression for the induceddistribution of the random partition, the fundamental tool regulating theclustering behavior of the model. On the one hand, this allows to gain a deeperinsight into the theoretical properties of the model and, on the other hand, ityields an MCMC algorithm for evaluating Bayesian inferences of interest.Moreover, we single out limitations of this algorithm when working with morethan two populations and, consequently, devise an alternative more efficientsampling scheme, which as a by-product, allows testing homogeneity betweendifferent populations. Finally, we perform a comparison with the nestedDirichlet process and provide illustrative examples of both synthetic and realdata.;
Arxiv;Bayesian mixture models (in)consistency for the number of clusters;Louise Alamichel;Daria Bystrova,Julyan Arbel,Guillaume Kon Kam King;2022/10/25;http://arxiv.org/abs/2210.14201v2;Bayesian nonparametric mixture models are common for modeling complex data.While these models are well-suited for density estimation, their applicationfor clustering has some limitations. Miller and Harrison (2014) provedposterior inconsistency in the number of clusters when the true number ofclusters is finite for Dirichlet process and Pitman--Yor process mixturemodels. In this work, we extend this result to additional Bayesiannonparametric priors such as Gibbs-type processes and finite-dimensionalrepresentations of them. The latter include the Dirichlet multinomial processand the recently proposed Pitman--Yor and normalized generalized gammamultinomial processes. We show that mixture models based on these processes arealso inconsistent in the number of clusters and discuss possible solutions.Notably, we show that a post-processing algorithm introduced by Guha et al.(2021) for the Dirichlet process extends to more general models and provides aconsistent method to estimate the number of components.;
Arxiv;A Bayesian View of the Poisson-Dirichlet Process;Wray Buntine;Marcus Hutter;2010/07/02;http://arxiv.org/abs/1007.0296v2;The two parameter Poisson-Dirichlet Process (PDP), a generalisation of theDirichlet Process, is increasingly being used for probabilistic modelling indiscrete areas such as language technology, bioinformatics, and image analysis.There is a rich literature about the PDP and its derivative distributions suchas the Chinese Restaurant Process (CRP). This article reviews some of the basictheory and then the major results needed for Bayesian modelling of discreteproblems including details of priors, posteriors and computation.  The PDP allows one to build distributions over countable partitions. The PDPhas two other remarkable properties: first it is partially conjugate to itself,which allows one to build hierarchies of PDPs, and second using a marginalisedrelative the CRP, one gets fragmentation and clustering properties that letsone layer partitions to build trees. This article presents the basic theory forunderstanding the notion of partitions and distributions over them, the PDP andthe CRP, and the important properties of conjugacy, fragmentation andclustering, as well as some key related properties such as consistency andconvergence. This article also presents a Bayesian interpretation of thePoisson-Dirichlet process based on an improper and infinite dimensionalDirichlet distribution. This means we can understand the process as justanother Dirichlet and thus all its sampling properties emerge naturally.  The theory of PDPs is usually presented for continuous distributions (moregenerally referred to as non-atomic distributions), however, when applied todiscrete distributions its remarkable conjugacy property emerges. This contextand basic results are also presented, as well as techniques for computing thesecond order Stirling numbers that occur in the posteriors for discretedistributions.;
Arxiv;Unsupervised Outlier Detection using Random Subspace and Subsampling  Ensembles of Dirichlet Process Mixtures;Dongwook Kim;Juyeon Park,Hee Cheol Chung,Seonghyun Jeong;2024/01/01;http://arxiv.org/abs/2401.00773v1;Probabilistic mixture models are acknowledged as a valuable tool forunsupervised outlier detection owing to their interpretability and intuitivegrounding in statistical principles. Within this framework, Dirichlet processmixture models emerge as a compelling alternative to conventional finitemixture models for both clustering and outlier detection tasks. However,despite their evident advantages, the widespread adoption of Dirichlet processmixture models in unsupervised outlier detection has been hampered bychallenges related to computational inefficiency and sensitivity to outliersduring the construction of detectors. To tackle these challenges, we propose anovel outlier detection method based on ensembles of Dirichlet process Gaussianmixtures. The proposed method is a fully unsupervised algorithm thatcapitalizes on random subspace and subsampling ensembles, not only ensuringefficient computation but also enhancing the robustness of the resultingoutlier detector. Moreover, the proposed method leverages variational inferencefor Dirichlet process mixtures to ensure efficient and fast computation.Empirical studies with benchmark datasets demonstrate that our methodoutperforms existing approaches for unsupervised outlier detection.;
Arxiv;From here to infinity - sparse finite versus Dirichlet process mixtures  in model-based clustering;Sylvia Fr√ºhwirth-Schnatter;Gertraud Malsiner-Walli;2017/06/22;http://arxiv.org/abs/1706.07194v3;In model-based-clustering mixture models are used to group data points intoclusters. A useful concept introduced for Gaussian mixtures by Malsiner Walliet al (2016) are sparse finite mixtures, where the prior distribution on theweight distribution of a mixture with $K$ components is chosen in such a waythat a priori the number of clusters in the data is random and is allowed to besmaller than $K$ with high probability. The number of cluster is then inferreda posteriori from the data.  The present paper makes the following contributions in the context of sparsefinite mixture modelling. First, it is illustrated that the concept of sparsefinite mixture is very generic and easily extended to cluster various types ofnon-Gaussian data, in particular discrete data and continuous multivariate dataarising from non-Gaussian clusters. Second, sparse finite mixtures are comparedto Dirichlet process mixtures with respect to their ability to identify thenumber of clusters. For both model classes, a random hyper prior is consideredfor the parameters determining the weight distribution. By suitable matching ofthese priors, it is shown that the choice of this hyper prior is far moreinfluential on the cluster solution than whether a sparse finite mixture or aDirichlet process mixture is taken into consideration.;
Arxiv;Flexible Priors for Exemplar-based Clustering;Daniel Tarlow;Richard S. Zemel,Brendan J. Frey;2012/06/13;http://arxiv.org/abs/1206.3294v1;"Exemplar-based clustering methods have been shown to produce state-of-the-artresults on a number of synthetic and real-world clustering problems. They areappealing because they offer computational benefits over latent-mean models andcan handle arbitrary pairwise similarity measures between data points. However,when trying to recover underlying structure in clustering problems, tailoredsimilarity measures are often not enough; we also desire control over thedistribution of cluster sizes. Priors such as Dirichlet process priors allowthe number of clusters to be unspecified while expressing priors over datapartitions. To our knowledge, they have not been applied to exemplar-basedmodels. We show how to incorporate priors, including Dirichlet process priors,into the recently introduced affinity propagation algorithm. We develop anefficient maxproduct belief propagation algorithm for our new model anddemonstrate experimentally how the expanded range of clustering priors allowsus to better recover true clusterings in situations where we have someinformation about the generating process.";
Arxiv;Parallel Clustering of Single Cell Transcriptomic Data with Split-Merge  Sampling on Dirichlet Process Mixtures;Tiehang Duan;Jos√© P. Pinto,Xiaohui Xie;2018/12/25;http://arxiv.org/abs/1812.10048v1;"Motivation: With the development of droplet based systems, massive singlecell transcriptome data has become available, which enables analysis ofcellular and molecular processes at single cell resolution and is instrumentalto understanding many biological processes. While state-of-the-art clusteringmethods have been applied to the data, they face challenges in the followingaspects: (1) the clustering quality still needs to be improved; (2) most modelsneed prior knowledge on number of clusters, which is not always available; (3)there is a demand for faster computational speed. Results: We propose to tacklethese challenges with Parallel Split Merge Sampling on Dirichlet ProcessMixture Model (the Para-DPMM model). Unlike classic DPMM methods that performsampling on each single data point, the split merge mechanism samples on thecluster level, which significantly improves convergence and optimality of theresult. The model is highly parallelized and can utilize the computing power ofhigh performance computing (HPC) clusters, enabling massive clustering on hugedatasets. Experiment results show the model outperforms current widely usedmodels in both clustering quality and computational speed. Availability: Sourcecode is publicly available onhttps://github.com/tiehangd/Para_DPMM/tree/master/Para_DPMM_package";
Arxiv;Tensor Dirichlet Process Multinomial Mixture Model for Passenger  Trajectory Clustering;Ziyue Li;Hao Yan,Chen Zhang,Andi Wang,Wolfgang Ketter,Lijun Sun,Fugee Tsung;2023/06/23;http://arxiv.org/abs/2306.13794v1;"Passenger clustering based on travel records is essential for transportationoperators. However, existing methods cannot easily cluster the passengers dueto the hierarchical structure of the passenger trip information, namely: eachpassenger has multiple trips, and each trip contains multi-dimensionalmulti-mode information. Furthermore, existing approaches rely on an accuratespecification of the clustering number to start, which is difficult whenmillions of commuters are using the transport systems on a daily basis. In thispaper, we propose a novel Tensor Dirichlet Process Multinomial Mixture model(Tensor-DPMM), which is designed to preserve the multi-mode and hierarchicalstructure of the multi-dimensional trip information via tensor, and clusterthem in a unified one-step manner. The model also has the ability to determinethe number of clusters automatically by using the Dirichlet Process to decidethe probabilities for a passenger to be either assigned in an existing clusteror to create a new cluster: This allows our model to grow the clusters asneeded in a dynamic manner. Finally, existing methods do not consider spatialsemantic graphs such as geographical proximity and functional similaritybetween the locations, which may cause inaccurate clustering. To this end, wefurther propose a variant of our model, namely the Tensor-DPMM with Graph. Forthe algorithm, we propose a tensor Collapsed Gibbs Sampling method, with aninnovative step of ""disband and relocating"", which disbands clusters with toosmall amount of members and relocates them to the remaining clustering. Thisavoids uncontrollable growing amounts of clusters. A case study based on HongKong metro passenger data is conducted to demonstrate the automatic process oflearning the number of clusters, and the learned clusters are better inwithin-cluster compactness and cross-cluster separateness.";
Arxiv;Hierarchical Latent Word Clustering;Halid Ziya Yerebakan;Fitsum Reda,Yiqiang Zhan,Yoshihisa Shinagawa;2016/01/20;http://arxiv.org/abs/1601.05472v1;This paper presents a new Bayesian non-parametric model by extending theusage of Hierarchical Dirichlet Allocation to extract tree structured wordclusters from text data. The inference algorithm of the model collects words ina cluster if they share similar distribution over documents. In ourexperiments, we observed meaningful hierarchical structures on NIPS corpus andradiology reports collected from public repositories.;
Arxiv;An efficient algorithm for solving elliptic problems on percolation  clusters;Chenlin Gu;;2019/07/31;http://arxiv.org/abs/1907.13571v1;We present an efficient algorithm to solve elliptic Dirichlet problemsdefined on the cluster of $\mathbb{Z}^d$ supercritical Bernoulli percolation,as a generalization of the iterative method proposed by S. Armstrong, A.Hannukainen, T. Kuusi and J.-C. Mourrat. We also explore the two-scaleexpansion on the infinite cluster of percolation, and use it to give a rigorousanalysis of the algorithm.;
Arxiv;Colouring and breaking sticks: random distributions and heterogeneous  clustering;Peter J. Green;;2010/03/21;http://arxiv.org/abs/1003.3988v1;We begin by reviewing some probabilistic results about the Dirichlet Processand its close relatives, focussing on their implications for statisticalmodelling and analysis. We then introduce a class of simple mixture models inwhich clusters are of different `colours', with statistical characteristicsthat are constant within colours, but different between colours. Thus clusteridentities are exchangeable only within colours. The basic form of our model isa variant on the familiar Dirichlet process, and we find that much of thestandard modelling and computational machinery associated with the Dirichletprocess may be readily adapted to our generalisation. The methodology isillustrated with an application to the partially-parametric clustering of geneexpression profiles.;
Arxiv;Beta-Product Poisson-Dirichlet Processes;Federico Bassetti;Roberto Casarin,Fabrizio Leisen;2011/09/22;http://arxiv.org/abs/1109.4777v1;Time series data may exhibit clustering over time and, in a multiple timeseries context, the clustering behavior may differ across the series. Thispaper is motivated by the Bayesian non--parametric modeling of the dependencebetween the clustering structures and the distributions of different timeseries. We follow a Dirichlet process mixture approach and introduce a newclass of multivariate dependent Dirichlet processes (DDP). The proposed DDP arerepresented in terms of vector of stick-breaking processes with dependentweights. The weights are beta random vectors that determine different anddependent clustering effects along the dimension of the DDP vector. We discusssome theoretical properties and provide an efficient Monte Carlo Markov Chainalgorithm for posterior computation. The effectiveness of the method isillustrated with a simulation study and an application to the United States andthe European Union industrial production indexes.;
Arxiv;Conjoined Dirichlet Process;Michelle N. Ngo;Dustin S. Pluta,Alexander N. Ngo,Babak Shahbaba;2020/02/08;http://arxiv.org/abs/2002.03223v1;Biclustering is a class of techniques that simultaneously clusters the rowsand columns of a matrix to sort heterogeneous data into homogeneous blocks.Although many algorithms have been proposed to find biclusters, existingmethods suffer from the pre-specification of the number of biclusters or placeconstraints on the model structure. To address these issues, we develop anovel, non-parametric probabilistic biclustering method based on Dirichletprocesses to identify biclusters with strong co-occurrence in both rows andcolumns. The proposed method utilizes dual Dirichlet process mixture models tolearn row and column clusters, with the number of resulting clusters determinedby the data rather than pre-specified. Probabilistic biclusters are identifiedby modeling the mutual dependence between the row and column clusters. We applyour method to two different applications, text mining and gene expressionanalysis, and demonstrate that our method improves bicluster extraction in manysettings compared to existing approaches.;
Arxiv;On the Variational Posterior of Dirichlet Process Deep Latent Gaussian  Mixture Models;Amine Echraibi;Joachim Flocon-Cholet,St√©phane Gosselin,Sandrine Vaton;2020/06/16;http://arxiv.org/abs/2006.08993v2;Thanks to the reparameterization trick, deep latent Gaussian models haveshown tremendous success recently in learning latent representations. Theability to couple them however with nonparamet-ric priors such as the DirichletProcess (DP) hasn't seen similar success due to its non parameteriz-ablenature. In this paper, we present an alternative treatment of the variationalposterior of the Dirichlet Process Deep Latent Gaussian Mixture Model(DP-DLGMM), where we show that the prior cluster parameters and the variationalposteriors of the beta distributions and cluster hidden variables can beupdated in closed-form. This leads to a standard reparameterization trick onthe Gaussian latent variables knowing the cluster assignments. We demonstrateour approach on standard benchmark datasets, we show that our model is capableof generating realistic samples for each cluster obtained, and manifestscompetitive performance in a semi-supervised setting.;
Arxiv;Powered Hawkes-Dirichlet Process: Challenging Textual Clustering using a  Flexible Temporal Prior;Ga√´l Poux-M√©dard;Julien Velcin,Sabine Loudcher;2021/09/15;http://arxiv.org/abs/2109.07170v1;The textual content of a document and its publication date are intertwined.For example, the publication of a news article on a topic is influenced byprevious publications on similar issues, according to underlying temporaldynamics. However, it can be challenging to retrieve meaningful informationwhen textual information conveys little information or when temporal dynamicsare hard to unveil. Furthermore, the textual content of a document is notalways linked to its temporal dynamics. We develop a flexible method to createclusters of textual documents according to both their content and publicationtime, the Powered Dirichlet-Hawkes process (PDHP). We show PDHP yieldssignificantly better results than state-of-the-art models when temporalinformation or textual content is weakly informative. The PDHP also alleviatesthe hypothesis that textual content and temporal dynamics are always perfectlycorrelated. PDHP allows retrieving textual clusters, temporal clusters, or amixture of both with high accuracy when they are not. We demonstrate that PDHPgeneralizes previous work --such as the Dirichlet-Hawkes process (DHP) andUniform process (UP). Finally, we illustrate the changes induced by PDHP overDHP and UP in a real-world application using Reddit data.;
Arxiv;Similarity-based Random Partition Distribution for Clustering Functional  Data;Tomoya Wakayama;Shonosuke Sugasawa,Genya Kobayashi;2023/08/03;http://arxiv.org/abs/2308.01704v2;Random partition distribution is a crucial tool for model-based clustering.This study advances the field of random partition in the context of functionalspatial data, focusing on the challenges posed by hourly population data acrossvarious regions and dates. We propose an extended generalized Dirichletprocess, named the similarity-based generalized Dirichlet process (SGDP), toaddress the limitations of simple random partition distributions (e.g., thoseinduced by the Dirichlet process), such as an overabundance of clusters. Thismodel prevents producing excess clusters as well as incorporates pairwisesimilarity information to ensure a more accurate and meaningful grouping. Thetheoretical properties of SGDP are studied. Then, SGDP is applied to areal-world dataset of hourly population flows in 500$\rm{m}^2$ meshes in thecentral part of Tokyo. In this empirical context, SGDP excelled at detectingmeaningful patterns in the data while accounting for spatial nuances. Theresults underscore the adaptability and utility of the method, showcasing itsprowess in revealing intricate spatiotemporal dynamics. This study's findingscontribute significantly to urban planning, transportation, and policy-makingby providing a helpful tool for understanding population dynamics and theirimplications.;
Arxiv;Nonparametric Variable Selection, Clustering and Prediction for  High-Dimensional Regression;Subharup Guha;Veerabhadran Baladandayuthapani;2014/07/21;http://arxiv.org/abs/1407.5472v3;The development of parsimonious models for reliable inference and predictionof responses in high-dimensional regression settings is often challenging dueto relatively small sample sizes and the presence of complex interactionpatterns between a large number of covariates. We propose an efficient,nonparametric framework for simultaneous variable selection, clustering andprediction in high-throughput regression settings with continuous or discreteoutcomes, called VariScan. The VariScan model utilizes the sparsity induced byPoisson-Dirichlet processes (PDPs) to group the covariates intolower-dimensional latent clusters consisting of covariates with similarpatterns among the samples. The data are permitted to direct the choice of asuitable cluster allocation scheme, choosing between PDPs and their specialcase, a Dirichlet process. Subsequently, the latent clusters are used to builda nonlinear prediction model for the responses using an adaptive mixture oflinear and nonlinear elements, thus achieving a balance between model parsimonyand flexibility. We investigate theoretical properties of the VariScanprocedure that differentiate the allocations patterns of PDPs and Dirichletprocesses both in terms of the number and relative sizes of their clusters.Additional theoretical results guarantee the high accuracy of the model-basedclustering procedure, and establish model selection and prediction consistency.Through simulation studies and analyses of benchmark data sets, we demonstratethe reliability of VariScan's clustering mechanism and show that the techniquecompares favorably to, and often outperforms, existing methodologies in termsof the prediction accuracies of the subject-specific responses.;
Arxiv;Fair Clustering via Hierarchical Fair-Dirichlet Process;Abhisek Chakraborty;Anirban Bhattacharya,Debdeep Pati;2023/05/27;http://arxiv.org/abs/2305.17557v1;The advent of ML-driven decision-making and policy formation has led to anincreasing focus on algorithmic fairness. As clustering is one of the mostcommonly used unsupervised machine learning approaches, there has naturallybeen a proliferation of literature on {\em fair clustering}. A popular notionof fairness in clustering mandates the clusters to be {\em balanced}, i.e.,each level of a protected attribute must be approximately equally representedin each cluster. Building upon the original framework, this literature hasrapidly expanded in various aspects. In this article, we offer a novelmodel-based formulation of fair clustering, complementing the existingliterature which is almost exclusively based on optimizing appropriateobjective functions.;
Arxiv;DIVA: A Dirichlet Process Mixtures Based Incremental Deep Clustering  Algorithm via Variational Auto-Encoder;Zhenshan Bing;Yuan Meng,Yuqi Yun,Hang Su,Xiaojie Su,Kai Huang,Alois Knoll;2023/05/23;http://arxiv.org/abs/2305.14067v3;"Generative model-based deep clustering frameworks excel in classifyingcomplex data, but are limited in handling dynamic and complex features becausethey require prior knowledge of the number of clusters. In this paper, wepropose a nonparametric deep clustering framework that employs an infinitemixture of Gaussians as a prior. Our framework utilizes a memoized onlinevariational inference method that enables the ""birth"" and ""merge"" moves ofclusters, allowing our framework to cluster data in a ""dynamic-adaptive""manner, without requiring prior knowledge of the number of features. We namethe framework as DIVA, a Dirichlet Process-based Incremental deep clusteringframework via Variational Auto-Encoder. Our framework, which outperformsstate-of-the-art baselines, exhibits superior performance in classifyingcomplex data with dynamically changing features, particularly in the case ofincremental features. We released our source code implementation at:https://github.com/Ghiara/diva";
Arxiv;Product Centered Dirichlet Processes for Dependent Clustering;Alexander Dombowsky;David B. Dunson;2023/12/08;http://arxiv.org/abs/2312.05365v1;While there is an immense literature on Bayesian methods for clustering, themultiview case has received little attention. This problem focuses on obtainingdistinct but statistically dependent clusterings in a common set of entitiesfor different data types. For example, clustering patients into subgroups withsubgroup membership varying according to the domain of the patient variables. Achallenge is how to model the across-view dependence between the partitions ofpatients into subgroups. The complexities of the partition space make standardmethods to model dependence, such as correlation, infeasible. In this article,we propose CLustering with Independence Centering (CLIC), a clustering priorthat uses a single parameter to explicitly model dependence between clusteringsacross views. CLIC is induced by the product centered Dirichlet process (PCDP),a novel hierarchical prior that bridges between independent and equivalentpartitions. We show appealing theoretic properties, provide a finiteapproximation and prove its accuracy, present a marginal Gibbs sampler forposterior computation, and derive closed form expressions for the marginal andjoint partition distributions for the CLIC model. On synthetic data and in anapplication to epidemiology, CLIC accurately characterizes view-specificpartitions while providing inference on the dependence level.;
Arxiv;Invariant Percolation and Harmonic Dirichlet Functions;Damien Gaboriau;;2004/05/24;http://arxiv.org/abs/math/0405458v3;The main goal of this paper is to answer question 1.10 and settle conjecture1.11 of Benjamini-Lyons-Schramm [BLS99] relating harmonic Dirichlet functionson a graph to those of the infinite clusters in the uniqueness phase ofBernoulli percolation. We extend the result to more general invariantpercolations, including the Random-Cluster model. We prove the existence of thenonuniqueness phase for the Bernoulli percolation (and make some progress forRandom-Cluster model) on unimodular transitive locally finite graphs admittingnonconstant harmonic Dirichlet functions. This is done by using the device of$\ell^2$ Betti numbers.;
Arxiv;Bayesian Nonparametric Multilevel Clustering with Group-Level Contexts;Vu Nguyen;Dinh Phung,XuanLong Nguyen,Svetha Venkatesh,Hung Hai Bui;2014/01/09;http://arxiv.org/abs/1401.1974v4;We present a Bayesian nonparametric framework for multilevel clustering whichutilizes group-level context information to simultaneously discoverlow-dimensional structures of the group contents and partitions groups intoclusters. Using the Dirichlet process as the building block, our modelconstructs a product base-measure with a nested structure to accommodatecontent and context observations at multiple levels. The proposed modelpossesses properties that link the nested Dirichlet processes (nDP) and theDirichlet process mixture models (DPM) in an interesting way: integrating outall contents results in the DPM over contexts, whereas integrating outgroup-specific contexts results in the nDP mixture over content variables. Weprovide a Polya-urn view of the model and an efficient collapsed Gibbsinference procedure. Extensive experiments on real-world datasets demonstratethe advantage of utilizing context information via our model in both text andimage domains.;
Arxiv;Choose A Table: Tensor Dirichlet Process Multinomial Mixture Model with  Graphs for Passenger Trajectory Clustering;Ziyue Li;Hao Yan,Chen Zhang,Lijun Sun,Wolfgang Ketter,Fugee Tsung;2023/10/31;http://arxiv.org/abs/2310.20224v1;Passenger clustering based on trajectory records is essential fortransportation operators. However, existing methods cannot easily cluster thepassengers due to the hierarchical structure of the passenger trip information,including multiple trips within each passenger and multi-dimensionalinformation about each trip. Furthermore, existing approaches rely on anaccurate specification of the clustering number to start. Finally, existingmethods do not consider spatial semantic graphs such as geographical proximityand functional similarity between the locations. In this paper, we propose anovel tensor Dirichlet Process Multinomial Mixture model with graphs, which canpreserve the hierarchical structure of the multi-dimensional trip informationand cluster them in a unified one-step manner with the ability to determine thenumber of clusters automatically. The spatial graphs are utilized in communitydetection to link the semantic neighbors. We further propose a tensor versionof Collapsed Gibbs Sampling method with a minimum cluster size requirement. Acase study based on Hong Kong metro passenger data is conducted to demonstratethe automatic process of cluster amount evolution and better cluster qualitymeasured by within-cluster compactness and cross-cluster separateness. The codeis available at https://github.com/bonaldli/TensorDPMM-G.;
Arxiv;Gibbs Sampling for (Coupled) Infinite Mixture Models in the Stick  Breaking Representation;Ian Porteous;Alexander T. Ihler,Padhraic Smyth,Max Welling;2012/06/27;http://arxiv.org/abs/1206.6845v1;Nonparametric Bayesian approaches to clustering, information retrieval,language modeling and object recognition have recently shown great promise as anew paradigm for unsupervised data analysis. Most contributions have focused onthe Dirichlet process mixture models or extensions thereof for which efficientGibbs samplers exist. In this paper we explore Gibbs samplers for infinitecomplexity mixture models in the stick breaking representation. The advantageof this representation is improved modeling flexibility. For instance, one candesign the prior distribution over cluster sizes or couple multiple infinitemixture models (e.g. over time) at the level of their parameters (i.e. thedependent Dirichlet process model). However, Gibbs samplers for infinitemixture models (as recently introduced in the statistics literature) seem tomix poorly over cluster labels. Among others issues, this can have the adverseeffect that labels for the same cluster in coupled mixture models are mixed up.We introduce additional moves in these samplers to improve mixing over clusterlabels and to bring clusters into correspondence. An application to modeling ofstorm trajectories is used to illustrate these ideas.;
Arxiv;Functional clustering in nested designs: Modeling variability in  reproductive epidemiology studies;Abel Rodriguez;David B. Dunson;2014/11/20;http://arxiv.org/abs/1411.5510v1;We discuss functional clustering procedures for nested designs, wheremultiple curves are collected for each subject in the study. We start byconsidering the application of standard functional clustering tools to thisproblem, which leads to groupings based on the average profile for eachsubject. After discussing some of the shortcomings of this approach, we presenta mixture model based on a generalization of the nested Dirichlet process thatclusters subjects based on the distribution of their curves. By using mixturesof generalized Dirichlet processes, the model induces a much more flexibleprior on the partition structure than other popular model-based clusteringmethods, allowing for different rates of introduction of new clusters as thenumber of observations increases. The methods are illustrated using hormoneprofiles from multiple menstrual cycles collected for women in the EarlyPregnancy Study.;
Arxiv;Posterior Distribution for the Number of Clusters in Dirichlet Process  Mixture Models;Chiao-Yu Yang;Eric Xia,Nhat Ho,Michael I. Jordan;2019/05/23;http://arxiv.org/abs/1905.09959v2;Dirichlet process mixture models (DPMM) play a central role in Bayesiannonparametrics, with applications throughout statistics and machine learning.DPMMs are generally used in clustering problems where the number of clusters isnot known in advance, and the posterior distribution is treated as providinginference for this number. Recently, however, it has been shown that the DPMMis inconsistent in inferring the true number of components in certain cases.This is an asymptotic result, and it would be desirable to understand whetherit holds with finite samples, and to more fully understand the full posterior.In this work, we provide a rigorous study for the posterior distribution of thenumber of clusters in DPMM under different prior distributions on theparameters and constraints on the distributions of the data. We provide novellower bounds on the ratios of probabilities between $s+1$ clusters and $s$clusters when the prior distributions on parameters are chosen to be Gaussianor uniform distributions.;
Arxiv;Topic Detection from Conversational Dialogue Corpus with Parallel  Dirichlet Allocation Model and Elbow Method;Haider Khalid;Vincent Wade;2020/06/05;http://arxiv.org/abs/2006.03353v1;A conversational system needs to know how to switch between topics tocontinue the conversation for a more extended period. For this topic detectionfrom dialogue corpus has become an important task for a conversation andaccurate prediction of conversation topics is important for creating coherentand engaging dialogue systems. In this paper, we proposed a topic detectionapproach with Parallel Latent Dirichlet Allocation (PLDA) Model by clustering avocabulary of known similar words based on TF-IDF scores and Bag of Words (BOW)technique. In the experiment, we use K-mean clustering with Elbow Method forinterpretation and validation of consistency within-cluster analysis to selectthe optimal number of clusters. We evaluate our approach by comparing it withtraditional LDA and clustering technique. The experimental results show thatcombining PLDA with Elbow method selects the optimal number of clusters andrefine the topics for the conversation.;
Arxiv;Bayesian nonparametric temporal dynamic clustering via autoregressive  Dirichlet priors;Maria De Iorio;Stefano Favaro,Alessandra Guglielmi,Lifeng Ye;2019/10/23;http://arxiv.org/abs/1910.10443v1;"In this paper we consider the problem of dynamic clustering, where clustermemberships may change over time and clusters may split and merge over time,thus creating new clusters and destroying existing ones. We propose a Bayesiannonparametric approach to dynamic clustering via mixture modeling. Our approachrelies on a novel time-dependent nonparametric prior defined by combining: i) acopula-based transformation of a Gaussian autoregressive process; ii) thestick-breaking construction of the Dirichlet process. Posterior inference isperformed through a particle Markov chain Monte Carlo algorithm which issimple, computationally efficient and scalable to massive datasets. Advantagesof the proposed approach include flexibility in applications, ease ofcomputations and interpretability. We present an application of our dynamicBayesian nonparametric mixture model to the study the temporal dynamics ofgender stereotypes in adjectives and occupations in the 20th and 21st centuriesin the United States. Moreover, to highlight the flexibility of our model wepresent additional applications to time-dependent data with covariates and withspatial structure.";
Arxiv;Joint Clustering and Registration of Functional Data;Yafeng Zhang;Donatello Telesca;2014/03/27;http://arxiv.org/abs/1403.7134v1;Curve registration and clustering are fundamental tools in the analysis offunctional data. While several methods have been developed and explored foreither task individually, limited work has been done to infer functionalclusters and register curves simultaneously. We propose a hierarchical modelfor joint curve clustering and registration. Our proposal combines a Dirichletprocess mixture model for clustering of common shapes, with a reproducingkernel representation of phase variability for registration. We show howinference can be carried out applying standard posterior simulation algorithmsand compare our method to several alternatives in both engineered data and abenchmark analysis of the Berkeley growth data. We conclude our investigationwith an application to time course gene expression.;
Arxiv;Heterogeneous Regression Models for Clusters of Spatial Dependent Data;Zhihua Ma;Yishu Xue,Guanyu Hu;2019/07/04;http://arxiv.org/abs/1907.02212v4;In economic development, there are often regions that share similar economiccharacteristics, and economic models on such regions tend to have similarcovariate effects. In this paper, we propose a Bayesian clustered regressionfor spatially dependent data in order to detect clusters in the covariateeffects. Our proposed method is based on the Dirichlet process which provides aprobabilistic framework for simultaneous inference of the number of clustersand the clustering configurations. The usage of our method is illustrated bothin simulation studies and an application to a housing cost dataset of Georgia.;
Arxiv;Dirichlet Fragmentation Processes;Hong Ge;Yarin Gal,Zoubin Ghahramani;2015/09/16;http://arxiv.org/abs/1509.04781v1;Tree structures are ubiquitous in data across many domains, and many datasetsare naturally modelled by unobserved tree structures. In this paper, first wereview the theory of random fragmentation processes [Bertoin, 2006], and anumber of existing methods for modelling trees, including the popular nestedChinese restaurant process (nCRP). Then we define a general class ofprobability distributions over trees: the Dirichlet fragmentation process (DFP)through a novel combination of the theory of Dirichlet processes and randomfragmentation processes. This DFP presents a stick-breaking construction, andrelates to the nCRP in the same way the Dirichlet process relates to theChinese restaurant process. Furthermore, we develop a novel hierarchicalmixture model with the DFP, and empirically compare the new model to similarmodels in machine learning. Experiments show the DFP mixture model to beconvincingly better than existing state-of-the-art approaches for hierarchicalclustering and density modelling.;
Arxiv;The semi-hierarchical Dirichlet Process and its application to  clustering homogeneous distributions;Mario Beraha;Alessandra Guglielmi,Fernando A. Quintana;2020/05/20;http://arxiv.org/abs/2005.10287v4;"Assessing homogeneity of distributions is an old problem that has receivedconsiderable attention, especially in the nonparametric Bayesian literature. Tothis effect, we propose the semi-hierarchical Dirichlet process, a novelhierarchical prior that extends the hierarchical Dirichlet process of Teh etal. (2006) and that avoids the degeneracy issues of nested processes recentlydescribed by Camerlenghi et al. (2019a). We go beyond the simple yes/no answerto the homogeneity question and embed the proposed prior in a random partitionmodel; this procedure allows us to give a more comprehensive response to theabove question and in fact find groups of populations that are internallyhomogeneous when I greater or equal than 2 such populations are considered. Westudy theoretical properties of the semi-hierarchical Dirichlet process and ofthe Bayes factor for the homogeneity test when I = 2. Extensive simulationstudies and applications to educational data are also discussed.";
