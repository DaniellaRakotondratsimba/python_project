Nature;Titre;Auteur;Co_Auteurs;Date;URL;Texte;Nb commentaires
Reddit;A very interesting and heartwarming concept;Tex-the-Dragon;;2024/01/09;https://www.reddit.com//r/interestingasfuck/comments/192fbsh/a_very_interesting_and_heartwarming_concept/;;612
Reddit;X Purges Prominent Journalists, Leftists With No Explanation;mcmeaningoflife42;;2024/01/09;https://www.reddit.com//r/technology/comments/192hc9s/x_purges_prominent_journalists_leftists_with_no/;;1687
Reddit;Willem Dafoe receives star on Hollywood Walk of Fame;unknown_human;;2024/01/09;https://www.reddit.com//r/pics/comments/192g0ez/willem_dafoe_receives_star_on_hollywood_walk_of/;;319
Reddit;A consequence of pressure difference;oklolzzzzs;;2024/01/09;https://www.reddit.com//r/Damnthatsinteresting/comments/192io9h/a_consequence_of_pressure_difference/;;208
Reddit;Absolutely disturbing but never surprising unfortunately.;The_Kyojuro_Rengoku;;2024/01/09;https://www.reddit.com//r/WitchesVsPatriarchy/comments/192i1gh/absolutely_disturbing_but_never_surprising/;;201
Reddit;Smacked by his own platform;GleamingBound;;2024/01/09;https://www.reddit.com//r/rareinsults/comments/192dvs0/smacked_by_his_own_platform/;;697
Reddit;Thanks for bringing this to our attention, Donny, Jr.;jared10011980;;2024/01/09;https://www.reddit.com//r/clevercomebacks/comments/192djza/thanks_for_bringing_this_to_our_attention_donny_jr/;;1102
Reddit;Watch: GOP Official Panics When Asked for Reason to Remove Biden From Ballot;thenewrepublic;;2024/01/09;https://www.reddit.com//r/politics/comments/192gd30/watch_gop_official_panics_when_asked_for_reason/;;668
Reddit;Me irl;TheWebsploiter;;2024/01/09;https://www.reddit.com//r/me_irl/comments/192dmnr/me_irl/;;893
Reddit;Christ, what an asshole;knivesofsmoothness;;2024/01/09;https://www.reddit.com//r/WhitePeopleTwitter/comments/192emh5/christ_what_an_asshole/;;599
Reddit;TIL Boeing pressured the US government to impose a 300% tariff on imports of Bombardier CSeries planes. The situation got bad enough that Canada filed a complaint at the WTO against the US. Eventually, Bombardier subsequently sold a 50.01% in the plane to Boeing's main competitor, Airbus, for $1.;PretendAsparaguso;;2024/01/09;https://www.reddit.com//r/todayilearned/comments/192dfwh/til_boeing_pressured_the_us_government_to_impose/;;815
Reddit;Asking the boys to craft the perfect text to her;Few_Independence7489;;2024/01/09;https://www.reddit.com//r/MadeMeSmile/comments/192ghac/asking_the_boys_to_craft_the_perfect_text_to_her/;;203
Reddit;Really brave;WorldlinessOk7796;;2024/01/09;https://www.reddit.com//r/facepalm/comments/192hj9u/really_brave/;;192
Reddit;=O.O=;Pizzacakecomic;;2024/01/09;https://www.reddit.com//r/comics/comments/192dfek/oo/;;486
Reddit;Jimmy Kimmel's monologue response tonight to Aaron Rodgers falsely accusing him of being on the Jeffrey Epstein list;SappyGilmore;;2024/01/09;https://www.reddit.com//r/sports/comments/192czfc/jimmy_kimmels_monologue_response_tonight_to_aaron/;;1553
Reddit;Boy comforts puppy scared of bath time;JovialJules;;2024/01/09;https://www.reddit.com//r/Awww/comments/192hw6d/boy_comforts_puppy_scared_of_bath_time/;;87
Reddit;My grey car is turning orange???;Raiceboi;;2024/01/09;https://www.reddit.com//r/cats/comments/192epc1/my_grey_car_is_turning_orange/;Shes slowly turning orange;698
Reddit;The wage theft crime wave strikes again;GrandpaChainz;;2024/01/09;https://www.reddit.com//r/WorkReform/comments/192hnz5/the_wage_theft_crime_wave_strikes_again/;;49
Reddit;Puritanical Feelings > Reality;TruCynic;;2024/01/09;https://www.reddit.com//r/antiwork/comments/192imfi/puritanical_feelings_reality/;;74
Reddit;That mug;NBL_123;;2024/01/09;https://www.reddit.com//r/mildlyinfuriating/comments/192bqiz/that_mug/;;653
Reddit;Training blindfolded;baddiebee22give;;2024/01/09;https://www.reddit.com//r/toptalent/comments/192gzuw/training_blindfolded/;;150
Reddit;Sinead O'Connor died of natural causes;Odd_Responsibility_5;;2024/01/09;https://www.reddit.com//r/news/comments/192ft75/sinead_oconnor_died_of_natural_causes/;;343
Reddit;Meirl;Dramatic_Carpet_6589;;2024/01/09;https://www.reddit.com//r/meirl/comments/192bgfw/meirl/;;266
Reddit;to target a commercial airplane ;HornyDiggler;;2024/01/09;https://www.reddit.com//r/therewasanattempt/comments/192fpqa/to_target_a_commercial_airplane/;;370
Reddit;Indeed!;Justthisdudeyaknow;;2024/01/09;https://www.reddit.com//r/CuratedTumblr/comments/192dr3l/indeed/;;550
Reddit;?;BagMean3089;;2024/01/09;https://www.reddit.com//r/ExplainTheJoke/comments/192dxzy/_/;;158
Reddit;A different approach ;Indieriots;;2024/01/09;https://www.reddit.com//r/funny/comments/192eu5x/a_different_approach/;Credit: @hassankhadair;158
Reddit;Birtherism comes for Nikki Haley;HeHateMe337;;2024/01/09;https://www.reddit.com//r/LeopardsAteMyFace/comments/192iy3v/birtherism_comes_for_nikki_haley/;;336
Reddit;Me and my sister 2004/2005;m-e-s-o;;2024/01/09;https://www.reddit.com//r/blunderyears/comments/192c1s6/me_and_my_sister_20042005/;"From First To Last had just dropped ""Dear diary...""  and every weekend was another alternative live show. For every cringe, there is also a great memory.";746
Reddit;The more you look, the more you see;Powerfluffgirl20;;2024/01/09;https://www.reddit.com//r/tumblr/comments/192ew0b/the_more_you_look_the_more_you_see/;;125
Reddit;Turntable;Daddys_Girlo;;2024/01/09;https://www.reddit.com//r/Funnymemes/comments/192d5qg/turntable/;;285
Reddit;The way this label saves space to write 'energy' in many languages;Eigenurin;;2024/01/09;https://www.reddit.com//r/mildlyinteresting/comments/192bz99/the_way_this_label_saves_space_to_write_energy_in/;;343
Reddit;Love has no boundaries (virgin edition);Ordinary-Bluebird979;;2024/01/09;https://www.reddit.com//r/shitposting/comments/192dd6t/love_has_no_boundaries_virgin_edition/;;384
Reddit;These three regions make up 50% of world GDP;redditor3000;;2024/01/09;https://www.reddit.com//r/MapPorn/comments/192hc1h/these_three_regions_make_up_50_of_world_gdp/;;421
Reddit;Knife defense techniques for noobs (that probably don't work);SixxRabbit;;2024/01/09;https://www.reddit.com//r/SipsTea/comments/192dxpk/knife_defense_techniques_for_noobs_that_probably/;;282
Reddit;Here's a reason to live longer;BayPangoro;;2024/01/09;https://www.reddit.com//r/pokemon/comments/192eass/heres_a_reason_to_live_longer/;;146
Reddit;Dope with a knife;WolfGodlives;;2024/01/09;https://www.reddit.com//r/WinStupidPrizes/comments/192garo/dope_with_a_knife/;;320
Reddit;"""Dorohedoro"" sequel anime announced";harushiga;;2024/01/09;https://www.reddit.com//r/anime/comments/192ai0e/dorohedoro_sequel_anime_announced/;;820
Reddit;TIL Korean astronauts eat a version of kimchi that has been radiated to kill all of the microorganisms;admiralturtleship;;2024/01/09;https://www.reddit.com//r/todayilearned/comments/192fcxc/til_korean_astronauts_eat_a_version_of_kimchi/;;124
Reddit;you are the reason they stay home.;diamondxxxl;;2024/01/09;https://www.reddit.com//r/rareinsults/comments/192f6l8/you_are_the_reason_they_stay_home/;;135
Reddit;The set of ‚ÄúCheers‚Äù from the actor‚Äôs perspective;bzlvrlwysfrvr0624;;2024/01/09;https://www.reddit.com//r/Damnthatsinteresting/comments/192eulm/the_set_of_cheers_from_the_actors_perspective/;‚ÄúCheers is filmed in front of a live studio audience‚Ä¶‚Äù;164
Reddit;My friends and I made an infographics with the best games of 2023 ranged by Metacritic;brontozawr;;2024/01/09;https://www.reddit.com//r/gaming/comments/192e9og/my_friends_and_i_made_an_infographics_with_the/;;823
Reddit;Cursed_hamster;wedaiebaldank;;2024/01/09;https://www.reddit.com//r/cursedcomments/comments/192ekie/cursed_hamster/;;78
Reddit;GOP frontrunner openly advocates for crashing the economy;8-bit-Felix;;2024/01/09;https://www.reddit.com//r/PoliticalHumor/comments/192dti5/gop_frontrunner_openly_advocates_for_crashing_the/;;197
Reddit;What's your opinion?;Competitive_Office68;;2024/01/09;https://www.reddit.com//r/AntiTrumpAlliance/comments/192eszn/whats_your_opinion/;;202
Reddit;I mean, little bit;OmegaBoi420;;2024/01/09;https://www.reddit.com//r/CloneWarsMemes/comments/192evf0/i_mean_little_bit/;;56
Reddit;Dude went in a 1v2 and still won;Ok-Arm8050;;2024/01/09;https://www.reddit.com//r/PublicFreakout/comments/192huh7/dude_went_in_a_1v2_and_still_won/;;197
Reddit;Ich_iel;abradolf__lincler_;;2024/01/09;https://www.reddit.com//r/ich_iel/comments/192gnxh/ich_iel/;;166
Reddit;The Hunger Games;Super_Emu_7291;;2024/01/09;https://www.reddit.com//r/FunnyandSad/comments/192git3/the_hunger_games/;;33
Reddit;Nightmare on a night out: Woman claims on TikTok that she accidentally ordered a $2,400 cocktail;Outside_Mongoose_749;;2024/01/09;https://www.reddit.com//r/nottheonion/comments/192h6ng/nightmare_on_a_night_out_woman_claims_on_tiktok/;"‚ÄúShe said she thought the cocktail was called ""1890,"" and she assumed that was the price of the cocktail as well ‚Äî ¬£18.90 (or about $24 in U.S. dollars). The cocktail contained Cristal, an expensive brand of champagne, as well as ""30-year-old cognac"" and gold leaf, she said. She also said she was given a ""huge book to sign.""";296
Reddit;Samsung introduces the world's first transparent MicroLED screen at CES 2024;oblique_shockwave;;2024/01/09;https://www.reddit.com//r/BeAmazed/comments/1928qlq/samsung_introduces_the_worlds_first_transparent/;;1526
Reddit;I'm the only student in my online Fundamentals of Accounting class at City University of Seattle.;mydude356;;2024/01/09;https://www.reddit.com//r/college/comments/192gx1j/im_the_only_student_in_my_online_fundamentals_of/;Professor will be responding to my discussion board posts and I will have to respond back to get full credit. No problem.;92
Reddit;backToStackOverflowAgain;FelchingLegend;;2024/01/09;https://www.reddit.com//r/ProgrammerHumor/comments/192bngn/backtostackoverflowagain/;;270
Reddit;Bi_irl;BenevolentDinosaur;;2024/01/09;https://www.reddit.com//r/bi_irl/comments/192br0j/bi_irl/;;121
Reddit;Jon Favreau Set To Direct New 'Star Wars' Movie 'The Mandalorian & Grogu', Begins Production This Year;MarvelsGrantMan136;;2024/01/09;https://www.reddit.com//r/movies/comments/192jf6k/jon_favreau_set_to_direct_new_star_wars_movie_the/;;542
Reddit;My mom and dad‚Äôs first date, 1992;glitterycroissant;;2024/01/09;https://www.reddit.com//r/OldSchoolCool/comments/192f7j4/my_mom_and_dads_first_date_1992/;;201
Reddit;Second update- AITA for forcing my daughter to share a room;Fine-Neat3967;;2024/01/09;https://www.reddit.com//r/AITAH/comments/192iv9h/second_update_aita_for_forcing_my_daughter_to/;"We booked the tickets and we ended up not including the daughters mainly because they just kept complaining.Last night they came to ask me why I wouldn't buy it if I can't afford it and why can't they stay home alone. They said ""why don't you guys care about our comforts and privacy"" and ""you'll ruin the trip because we won't even have our own rooms which is a basic comfort"". They tried to convince us to let us stay home alone but the last time I did that my oldest threw a party so I don't trust them and even if I did I don't feel comfortable leaving them alone for a whole week.They threw another tantrum and I just told them they wouldn't be coming and it was final. I was going to leave them at my MIL but she wants to take our daughters on a 4 day trip to Sydney where they will get their own rooms she did this ""make up for us ruining the daughters trip by making them share a room and excluding them if they didn't"" but I just told her no because I've spoiled them too much and I'm not rewarding a tantrum.My sister didn't want to take them but my brother agreed to take them so I'll  be leaving them there where one of them has to sleep on the couch and the other on an air mattes as they don't have an extra room.My daughters have complained but they aren't coming This will probably be my final update thanks.";217
Reddit;Roger Stone reportedly said leading Democratic congressman ‚Äòhas to die‚Äô;nosotros_road_sodium;;2024/01/09;https://www.reddit.com//r/politics/comments/192h1fi/roger_stone_reportedly_said_leading_democratic/;;281
Reddit;Ukrainian Hacker Group Takes Down Moscow Internet Provider ‚Äì ‚ÄòRevenge for Kyivstar‚Äô;yorkiecd;;2024/01/09;https://www.reddit.com//r/worldnews/comments/192e7fi/ukrainian_hacker_group_takes_down_moscow_internet/;;75
Reddit;Erm‚Ä¶ Hello??;OggoChoggo;;2024/01/09;https://www.reddit.com//r/mapporncirclejerk/comments/192ehye/erm_hello/;;228
Reddit;Would you still get married?;Ordinary_Process_920;;2024/01/09;https://www.reddit.com//r/facepalm/comments/192gobq/would_you_still_get_married/;;156
Reddit;How would you respond;honeyyzzzx;;2024/01/09;https://www.reddit.com//r/TikTokCringe/comments/192dp5q/how_would_you_respond/;;119
Reddit;Soon to be my Mother-in-law;420Litten;;2024/01/09;https://www.reddit.com//r/insanepeoplefacebook/comments/192fklw/soon_to_be_my_motherinlaw/;;384
Reddit;Start a business with Colombian cheese. Good luck.;Usual_Key_9726;;2024/01/09;https://www.reddit.com//r/HolUp/comments/192dgbp/start_a_business_with_colombian_cheese_good_luck/;;70
Reddit;Meirl;-kyutiepie-;;2024/01/09;https://www.reddit.com//r/meirl/comments/192dpa9/meirl/;;24
Reddit;Regret [OC];MelonKony;;2024/01/09;https://www.reddit.com//r/comics/comments/192d6zb/regret_oc/;;124
Reddit;Mortuary Assistant Scares YouTuber;Mildred_Wolfenbarger;;2024/01/09;https://www.reddit.com//r/perfectlycutscreams/comments/192bs5k/mortuary_assistant_scares_youtuber/;;181
Reddit;It's curious to think about One Piece timeline;Ramondasetemeia;;2024/01/09;https://www.reddit.com//r/MemePiece/comments/192g0ki/its_curious_to_think_about_one_piece_timeline/;;66
Reddit;I've heard before that Paris smells like piss ;PansyParkinson80;;2024/01/09;https://www.reddit.com//r/Unexpected/comments/192b1uw/ive_heard_before_that_paris_smells_like_piss/;;887
Reddit;Disabled Cellist Gives Moving Performance;RevolutionaryTell668;;2024/01/09;https://www.reddit.com//r/MadeMeSmile/comments/192hu1u/disabled_cellist_gives_moving_performance/;;111
Reddit;This subreddit vs the rest of the world;ThiccAssCrackHead;;2024/01/09;https://www.reddit.com//r/motorcycles/comments/192h56p/this_subreddit_vs_the_rest_of_the_world/;;286
Reddit;--title has been lost--;eekfirebolt;;2024/01/09;https://www.reddit.com//r/MinecraftMemes/comments/192f4j4/title_has_been_lost/;;59
Reddit;When your adapting to situations come in handy;mrsrkfj;;2024/01/09;https://www.reddit.com//r/BlackPeopleTwitter/comments/192emoj/when_your_adapting_to_situations_come_in_handy/;;112
Reddit;Guard rail saves the day;Joey_Devoe;;2024/01/09;https://www.reddit.com//r/nonononoyes/comments/1929fn0/guard_rail_saves_the_day/;;179
Reddit;Babe wake up, new dream job just dropped;elvis-wantacookie;;2024/01/09;https://www.reddit.com//r/popculturechat/comments/192iirk/babe_wake_up_new_dream_job_just_dropped/;;114
Reddit;oopsie poopsie;constantlytired1917;;2024/01/09;https://www.reddit.com//r/dankmemes/comments/192c3ki/oopsie_poopsie/;;100
Reddit;Family Reunion;DragonDuChat;;2024/01/09;https://www.reddit.com//r/PrequelMemes/comments/1928gm9/family_reunion/;Source: https://twitter.com/MarkHamill/status/1744452324356190334?t=TIpJoBgIATZJIAlNEJilyw&s=19;283
Reddit;I got my car back from the shop six weeks ago, and only just realized...;Straight-Dish-7074;;2024/01/09;https://www.reddit.com//r/funny/comments/192hhp0/i_got_my_car_back_from_the_shop_six_weeks_ago_and/;;166
Reddit;If Skyrim was made in the 90s;hozzam11;;2024/01/09;https://www.reddit.com//r/skyrim/comments/192bdy3/if_skyrim_was_made_in_the_90s/;By the yt channel (Pertinax) ;244
Reddit;He thinks I can‚Äôt see him;No-Specific1660;;2024/01/09;https://www.reddit.com//r/cats/comments/192e91f/he_thinks_i_cant_see_him/;;150
Reddit;Why am I not rich yet?;lovelyxxy;;2024/01/09;https://www.reddit.com//r/technicallythetruth/comments/192fi7a/why_am_i_not_rich_yet/;;19
Reddit;Driving the first ever car from 1886 that was built by Mercedes-Benz;Far-Stay9417;;2024/01/09;https://www.reddit.com//r/interestingasfuck/comments/192cf5j/driving_the_first_ever_car_from_1886_that_was/;;509
Reddit;Where there‚Äôs a kitty there‚Äôs a way.;Umer_-;;2024/01/09;https://www.reddit.com//r/Eyebleach/comments/192fxhl/where_theres_a_kitty_theres_a_way/;;39
Reddit;France just designated it's first openly gay government leader (Prime Minister);NeimaDParis;;2024/01/09;https://www.reddit.com//r/europe/comments/192dghz/france_just_designated_its_first_openly_gay/;;706
Reddit;[Wojnarowski] Pacers star Tyrese Haliburton has a Grade 1 left hamstring strain, an MRI revealed on Tuesday, sources tell ESPN. He‚Äôs expected to be re-evaluated in approximately two weeks but there‚Äôs relief that he‚Äôs avoided serious injury.;MarvelsGrantMan136;;2024/01/09;https://www.reddit.com//r/nba/comments/192ipsd/wojnarowski_pacers_star_tyrese_haliburton_has_a/;;218
Reddit;A very tough decision;L3veLUP;;2024/01/09;https://www.reddit.com//r/CasualUK/comments/192hrp8/a_very_tough_decision/;;260
Reddit;üî• Speed of the hunt ;satishtreks;;2024/01/09;https://www.reddit.com//r/NatureIsFuckingLit/comments/192d5im/speed_of_the_hunt/;Source : https://www.instagram.com/reel/CzgK4iZqmsx/?igsh=MTA3YWM0MWlnZmNzZw==;203
Reddit;"This is the Republican's idea of ""winning."" They all need to be voted out of office";rhino910;;2024/01/09;https://www.reddit.com//r/WhitePeopleTwitter/comments/192ihao/this_is_the_republicans_idea_of_winning_they_all/;;56
Reddit;Use your nice stuff;mando0987654321;;2024/01/09;https://www.reddit.com//r/tumblr/comments/192eovq/use_your_nice_stuff/;;60
Reddit;UNBGBBIIVCHIDCTIICBG&Weeeeeeeeeeeeeeeeeee;2tooORtutu;;2024/01/09;https://www.reddit.com//r/UNBGBBIIVCHIDCTIICBG/comments/192gew3/unbgbbiivchidctiicbgweeeeeeeeeeeeeeeeeee/;;72
Reddit;Prove your humanity;Magical_Babez;;2024/01/09;https://www.reddit.com//r/meme/comments/192d7mt/prove_your_humanity/;;65
Reddit;Damn Athenians, you ruined Athens!;mcflymikes;;2024/01/09;https://www.reddit.com//r/RoughRomanMemes/comments/192glg4/damn_athenians_you_ruined_athens/;;28
Reddit;Heartfelt Moments in Futurama: Remembering Fry's Family üò¢üò¢üò¢;Not_Your_Girl_Max;;2024/01/09;https://www.reddit.com//r/wholesomememes/comments/1926zuc/heartfelt_moments_in_futurama_remembering_frys/;;363
Reddit;Aged HORRENDOUSLY;Lord_Answer_me_Why;;2024/01/09;https://www.reddit.com//r/agedlikemilk/comments/192ht4g/aged_horrendously/;;50
Reddit;I tried to look it up;No_Construction8839;;2024/01/09;https://www.reddit.com//r/PeterExplainsTheJoke/comments/192dok6/i_tried_to_look_it_up/;;57
Reddit;Spain makes masks mandatory in hospitals after spike in Covid and flu cases;madrid987;;2024/01/09;https://www.reddit.com//r/news/comments/192cx50/spain_makes_masks_mandatory_in_hospitals_after/;;287
Reddit;What everyday item do you think will become obsolete in the next 10 years, and why?;Electrical-Memory-81;;2024/01/09;https://www.reddit.com//r/AskReddit/comments/192dqwd/what_everyday_item_do_you_think_will_become/;;3416
Reddit;Booger Mcfarland: ‚ÄúNothing against JJ however he made 2-3 throws last night because they dominated the LOS and had great defense Just goes to show u it‚Äôs not always about the best quarterback. Sometimes it‚Äôs about the best team #seminoles. Let‚Äôs remember this going forward‚Äù;LamarcusAldrige1234;;2024/01/09;https://www.reddit.com//r/CFB/comments/192ghq2/booger_mcfarland_nothing_against_jj_however_he/;https://x.com/espnbooger/status/1744732561413402643?s=46&t=uS2bi20KkRN-hrVJHus7zQ;855
Reddit;Ordered flowers local to the recipient;LabRatPerson;;2024/01/09;https://www.reddit.com//r/ExpectationVsReality/comments/192glca/ordered_flowers_local_to_the_recipient/;First picture is the website picture. Always ordering from a florist local to the recipient from now on (not 1-800 flowers, etc).;54
Reddit;Mouse filmed tidying up man's shed every night;XXmynameisNeganXX;;2024/01/09;https://www.reddit.com//r/nextfuckinglevel/comments/192fkkw/mouse_filmed_tidying_up_mans_shed_every_night/;;125
Arxiv;Hierarchical Dirichlet Process and Relative Entropy;Shui Feng;;2022/10/24;http://arxiv.org/abs/2210.13142v1;The Hierarchical Dirichlet process is a discrete random measure serving as animportant prior in Bayesian non-parametrics. It is motivated with the study ofgroups of clustered data. Each group is modelled through a level two Dirichletprocess and all groups share the same base distribution which itself is a drawnfrom a level one Dirichlet process. It has two concentration parameters withone at each level. The main results of the paper are the law of large numbersand large deviations for the hierarchical Dirichlet process and its mass whenboth concentration parameters converge to infinity. The large deviation ratefunctions are identified explicitly. The rate function for the hierarchicalDirichlet process consists of two terms corresponding to the relative entropiesat each level. It is less than the rate function for the Dirichlet process,which reflects the fact that the number of clusters under the hierarchicalDirichlet process has a slower growth rate than under the Dirichlet process.;
Arxiv;Spectral analysis of communication networks using Dirichlet eigenvalues;Alexander Tsiatas;Iraj Saniee,Onuttom Narayan,Matthew Andrews;2011/02/17;http://arxiv.org/abs/1102.3722v2;"The spectral gap of the graph Laplacian with Dirichlet boundary conditions iscomputed for the graphs of several communication networks at the IP-layer,which are subgraphs of the much larger global IP-layer network. We show thatthe Dirichlet spectral gap of these networks is substantially larger than thestandard spectral gap and is likely to remain non-zero in the infinite graphlimit. We first prove this result for finite regular trees, and show that theDirichlet spectral gap in the infinite tree limit converges to the spectral gapof the infinite tree. We also perform Dirichlet spectral clustering on theIP-layer networks and show that it often yields cuts near the network core thatcreate genuine single-component clusters. This is much better than traditionalspectral clustering where several disjoint fragments near the periphery areliable to be misleadingly classified as a single cluster. Spectral clusteringis often used to identify bottlenecks or congestion; since congestion in thesenetworks is known to peak at the core, our results suggest that Dirichletspectral clustering may be better at finding bona-fide bottlenecks.";
Arxiv;Dirichlet Process Mixtures of Generalized Mallows Models;Marina Meila;Harr Chen;2012/03/15;http://arxiv.org/abs/1203.3496v1;We present a Dirichlet process mixture model over discrete incompleterankings and study two Gibbs sampling inference techniques for estimatingposterior clusterings. The first approach uses a slice sampling subcomponentfor estimating cluster parameters. The second approach marginalizes out severalcluster parameters by taking advantage of approximations to the conditionalposteriors. We empirically demonstrate (1) the effectiveness of thisapproximation for improving convergence, (2) the benefits of the Dirichletprocess model over alternative clustering techniques for ranked data, and (3)the applicability of the approach to exploring large realworld rankingdatasets.;
Arxiv;Clustering consistency with Dirichlet process mixtures;Filippo Ascolani;Antonio Lijoi,Giovanni Rebaudo,Giacomo Zanella;2022/05/25;http://arxiv.org/abs/2205.12924v1;Dirichlet process mixtures are flexible non-parametric models, particularlysuited to density estimation and probabilistic clustering. In this work westudy the posterior distribution induced by Dirichlet process mixtures as thesample size increases, and more specifically focus on consistency for theunknown number of clusters when the observed data are generated from a finitemixture. Crucially, we consider the situation where a prior is placed on theconcentration parameter of the underlying Dirichlet process. Previous findingsin the literature suggest that Dirichlet process mixtures are typically notconsistent for the number of clusters if the concentration parameter is heldfixed and data come from a finite mixture. Here we show that consistency forthe number of clusters can be achieved if the concentration parameter isadapted in a fully Bayesian way, as commonly done in practice. Our results arederived for data coming from a class of finite mixtures, with mild assumptionson the prior for the concentration parameter and for a variety of choices oflikelihood kernels for the mixture.;
Arxiv;A Hierarchical Dirichlet Process Model with Multiple Levels of  Clustering for Human EEG Seizure Modeling;Drausin Wulsin;Shane Jensen,Brian Litt;2012/06/18;http://arxiv.org/abs/1206.4616v1;Driven by the multi-level structure of human intracranialelectroencephalogram (iEEG) recordings of epileptic seizures, we introduce anew variant of a hierarchical Dirichlet Process---the multi-level clusteringhierarchical Dirichlet Process (MLC-HDP)---that simultaneously clustersdatasets on multiple levels. Our seizure dataset contains brain activityrecorded in typically more than a hundred individual channels for each seizureof each patient. The MLC-HDP model clusters over channels-types, seizure-types,and patient-types simultaneously. We describe this model and its implementationin detail. We also present the results of a simulation study comparing theMLC-HDP to a similar model, the Nested Dirichlet Process and finallydemonstrate the MLC-HDP's use in modeling seizures across multiple patients. Wefind the MLC-HDP's clustering to be comparable to independent human physicianclusterings. To our knowledge, the MLC-HDP model is the first in the epilepsyliterature capable of clustering seizures within and between patients.;
Arxiv;The supervised hierarchical Dirichlet process;Andrew M. Dai;Amos J. Storkey;2014/12/17;http://arxiv.org/abs/1412.5236v1;"We propose the supervised hierarchical Dirichlet process (sHDP), anonparametric generative model for the joint distribution of a group ofobservations and a response variable directly associated with that whole group.We compare the sHDP with another leading method for regression on grouped data,the supervised latent Dirichlet allocation (sLDA) model. We evaluate our methodon two real-world classification problems and two real-world regressionproblems. Bayesian nonparametric regression models based on the Dirichletprocess, such as the Dirichlet process-generalised linear models (DP-GLM) havepreviously been explored; these models allow flexibility in modelling nonlinearrelationships. However, until now, Hierarchical Dirichlet Process (HDP)mixtures have not seen significant use in supervised problems with grouped datasince a straightforward application of the HDP on the grouped data results inlearnt clusters that are not predictive of the responses. The sHDP solves thisproblem by allowing for clusters to be learnt jointly from the group structureand from the label assigned to each group.";
Arxiv;Scalable Inference for Latent Dirichlet Allocation;James Petterson;Tiberio Caetano;2009/09/25;http://arxiv.org/abs/0909.4603v1;We investigate the problem of learning a topic model - the well-known LatentDirichlet Allocation - in a distributed manner, using a cluster of C processorsand dividing the corpus to be learned equally among them. We propose a simpleapproximated method that can be tuned, trading speed for accuracy according tothe task at hand. Our approach is asynchronous, and therefore suitable forclusters of heterogenous machines.;
Arxiv;Dynamic Clustering via Asymptotics of the Dependent Dirichlet Process  Mixture;Trevor Campbell;Miao Liu,Brian Kulis,Jonathan P. How,Lawrence Carin;2013/05/28;http://arxiv.org/abs/1305.6659v2;This paper presents a novel algorithm, based upon the dependent Dirichletprocess mixture model (DDPMM), for clustering batch-sequential data containingan unknown number of evolving clusters. The algorithm is derived via alow-variance asymptotic analysis of the Gibbs sampling algorithm for the DDPMM,and provides a hard clustering with convergence guarantees similar to those ofthe k-means algorithm. Empirical results from a synthetic test with movingGaussian clusters and a test with real ADS-B aircraft trajectory datademonstrate that the algorithm requires orders of magnitude less computationaltime than contemporary probabilistic and hard clustering algorithms, whileproviding higher accuracy on the examined datasets.;
Arxiv;Dirichlet-tree multinomial mixtures for clustering microbiome  compositions;Jialiang Mao;Li Ma;2020/08/02;http://arxiv.org/abs/2008.00400v2;Studying the human microbiome has gained substantial interest in recentyears, and a common task in the analysis of these data is to cluster microbiomecompositions into subtypes. This subdivision of samples into subgroups servesas an intermediary step in achieving personalized diagnosis and treatment. Inapplying existing clustering methods to modern microbiome studies including theAmerican Gut Project (AGP) data, we found that this seemingly standard task,however, is very challenging in the microbiome composition context due toseveral key features of such data. Standard distance-based clusteringalgorithms generally do not produce reliable results as they do not take intoaccount the heterogeneity of the cross-sample variability among the bacterialtaxa, while existing model-based approaches do not allow sufficient flexibilityfor the identification of complex within-cluster variation from cross-clustervariation. Direct applications of such methods generally lead to overlydispersed clusters in the AGP data and such phenomenon is common for othermicrobiome data. To overcome these challenges, we introduce Dirichlet-treemultinomial mixtures (DTMM) as a Bayesian generative model for clusteringamplicon sequencing data in microbiome studies. DTMM models the microbiomepopulation with a mixture of Dirichlet-tree kernels that utilizes thephylogenetic tree to offer a more flexible covariance structure incharacterizing within-cluster variation, and it provides a means foridentifying a subset of signature taxa that distinguish the clusters. Weperform extensive simulation studies to evaluate the performance of DTMM andcompare it to state-of-the-art model-based and distance-based clusteringmethods in the microbiome context. Finally, we report a case study on the fecaldata from the AGP to identify compositional clusters among individuals withinflammatory bowel disease and diabetes.;
Arxiv;Percolation Perturbations in Potential Theory and Random Walks;Itai Benjamini;Russell Lyons,Oded Schramm;1998/04/02;http://arxiv.org/abs/math/9804010v1;We show that on a Cayley graph of a nonamenable group, almost surely theinfinite clusters of Bernoulli percolation are transient for simple randomwalk, that simple random walk on these clusters has positive speed, and thatthese clusters admit bounded harmonic functions. A principal new finding onwhich these results are based is that such clusters admit invariant randomsubgraphs with positive isoperimetric constant.  We also show that percolation clusters in any amenable Cayley graph almostsurely admit no nonconstant harmonic Dirichlet functions. Conversely, on aCayley graph admitting nonconstant harmonic Dirichlet functions, almost surelythe infinite clusters of $p$-Bernoulli percolation also have nonconstantharmonic Dirichlet functions when $p$ is sufficiently close to 1. Manyconjectures and questions are presented.;
Arxiv;Informed Bayesian Finite Mixture Models via Asymmetric Dirichlet Priors;Garritt L. Page;Massimo Ventrucci,Maria Franco-Villoria;2023/08/01;http://arxiv.org/abs/2308.00768v1;Finite mixture models are flexible methods that are commonly used formodel-based clustering. A recent focus in the model-based clustering literatureis to highlight the difference between the number of components in a mixturemodel and the number of clusters. The number of clusters is more relevant froma practical stand point, but to date, the focus of prior distributionformulation has been on the number of components. In light of this, we developa finite mixture methodology that permits eliciting prior information directlyon the number of clusters in an intuitive way. This is done by employing anasymmetric Dirichlet distribution as a prior on the weights of a finitemixture. Further, a penalized complexity motivated prior is employed for theDirichlet shape parameter. We illustrate the ease to which prior informationcan be elicited via our construction and the flexibility of the resultinginduced prior on the number of clusters. We also demonstrate the utility of ourapproach using numerical experiments and two real world data sets.;
Arxiv;Numerical conformal mapping with rational functions;Lloyd N. Trefethen;;2019/11/09;http://arxiv.org/abs/1911.03696v1;"New algorithms are presented for numerical conformal mapping based onrational approximations and the solution of Dirichlet problems by least-squaresfitting on the boundary. The methods are targeted at regions with corners,where the Dirichlet problem is solved by the ""lightning Laplace solver"" withpoles exponentially clustered near each singularity. For polygons and circularpolygons, further simplifications are possible.";
Arxiv;Revisiting k-means: New Algorithms via Bayesian Nonparametrics;Brian Kulis;Michael I. Jordan;2011/11/02;http://arxiv.org/abs/1111.0352v2;Bayesian models offer great flexibility for clusteringapplications---Bayesian nonparametrics can be used for modeling infinitemixtures, and hierarchical Bayesian models can be utilized for sharing clustersacross multiple data sets. For the most part, such flexibility is lacking inclassical clustering methods such as k-means. In this paper, we revisit thek-means clustering algorithm from a Bayesian nonparametric viewpoint. Inspiredby the asymptotic connection between k-means and mixtures of Gaussians, we showthat a Gibbs sampling algorithm for the Dirichlet process mixture approaches ahard clustering algorithm in the limit, and further that the resultingalgorithm monotonically minimizes an elegant underlying k-means-like clusteringobjective that includes a penalty for the number of clusters. We generalizethis analysis to the case of clustering multiple data sets through a similarasymptotic argument with the hierarchical Dirichlet process. We also discussfurther extensions that highlight the benefits of our analysis: i) a spectralrelaxation involving thresholded eigenvectors, and ii) a normalized cut graphclustering algorithm that does not fix the number of clusters in the graph.;
Arxiv;Bayesian Clustering of Transcription Factor Binding Motifs;Shane T. Jensen;Jun S. Liu;2006/10/22;http://arxiv.org/abs/math/0610655v1;Genes are often regulated in living cells by proteins called transcriptionfactors (TFs) that bind directly to short segments of DNA in close proximity tospecific genes. These binding sites have a conserved nucleotide appearance,which is called a motif. Several recent studies of transcriptional regulationrequire the reduction of a large collection of motifs into clusters based onthe similarity of their nucleotide composition. We present a principledapproach to this clustering problem based upon a Bayesian hierarchical modelthat accounts for both within- and between-motif variability. We use aDirichlet process prior distribution that allows the number of clusters to varyand we also present a novel generalization that allows the core width of eachmotif to vary. This clustering model is implemented, using a Gibbs samplingstrategy, on several collections of transcription factor motif matrices. Ourclusters provide a means by which to organize transcription factors based onbinding motif similarities, which can be used to reduce motif redundancy withinlarge databases such as JASPAR and TRANSFAC. Finally, our clustering procedurehas been used in combination with discovery of evolutionarily-conserved motifsto predict co-regulated genes. An alternative to our Dirichlet process priordistribution is explored but shows no substantive difference in the clusteringresults for our datasets. Our Bayesian clustering model based on the Dirichletprocess has several advantages over traditional clustering methods that couldmake our procedure appropriate and useful for many clustering applications.;
Arxiv;DIMM-SC: A Dirichlet mixture model for clustering droplet-based single  cell transcriptomic data;Zhe Sun;Ting Wang,Ke Deng,Xiao-Feng Wang,Robert Lafyatis,Ying Ding,Ming Hu,Wei Chen;2017/04/06;http://arxiv.org/abs/1704.02007v1;Motivation: Single cell transcriptome sequencing (scRNA-Seq) has become arevolutionary tool to study cellular and molecular processes at single cellresolution. Among existing technologies, the recently developed droplet-basedplatform enables efficient parallel processing of thousands of single cellswith direct counting of transcript copies using Unique Molecular Identifier(UMI). Despite the technology advances, statistical methods and computationaltools are still lacking for analyzing droplet-based scRNA-Seq data.Particularly, model-based approaches for clustering large-scale single celltranscriptomic data are still under-explored. Methods: We developed DIMM-SC, aDirichlet Mixture Model for clustering droplet-based Single Cell transcriptomicdata. This approach explicitly models UMI count data from scRNA-Seq experimentsand characterizes variations across different cell clusters via a Dirichletmixture prior. An expectation-maximization algorithm is used for parameterinference. Results: We performed comprehensive simulations to evaluate DIMM-SCand compared it with existing clustering methods such as K-means, CellTree andSeurat. In addition, we analyzed public scRNA-Seq datasets with known clusterlabels and in-house scRNA-Seq datasets from a study of systemic sclerosis withprior biological knowledge to benchmark and validate DIMM-SC. Both simulationstudies and real data applications demonstrated that overall, DIMM-SC achievessubstantially improved clustering accuracy and much lower clusteringvariability compared to other existing clustering methods. More importantly, asa model-based approach, DIMM-SC is able to quantify the clustering uncertaintyfor each single cell, facilitating rigorous statistical inference andbiological interpretations, which are typically unavailable from existingclustering methods.;
Arxiv;Graphical Dirichlet Process for Clustering Non-Exchangeable Grouped Data;Arhit Chakrabarti;Yang Ni,Ellen Ruth A. Morris,Michael L. Salinas,Robert S. Chapkin,Bani K. Mallick;2023/02/17;http://arxiv.org/abs/2302.09111v2;We consider the problem of clustering grouped data with possiblynon-exchangeable groups whose dependencies can be characterized by a knowndirected acyclic graph. To allow the sharing of clusters among thenon-exchangeable groups, we propose a Bayesian nonparametric approach, termedgraphical Dirichlet process, that jointly models the dependent group-specificrandom measures by assuming each random measure to be distributed as aDirichlet process whose concentration parameter and base probability measuredepend on those of its parent groups. The resulting joint stochastic processrespects the Markov property of the directed acyclic graph that links thegroups. We characterize the graphical Dirichlet process using a novelhypergraph representation as well as the stick-breaking representation, therestaurant-type representation, and the representation as a limit of a finitemixture model. We develop an efficient posterior inference algorithm andillustrate our model with simulations and a real grouped single-cell dataset.;
Arxiv;Consistency Analysis for the Doubly Stochastic Dirichlet Process;Xing Sun;Nelson H. C. Yung,Edmund Y. Lam,Hayden K. -H. So;2016/05/24;http://arxiv.org/abs/1605.07358v1;"This technical report proves components consistency for the Doubly StochasticDirichlet Process with exponential convergence of posterior probability. Wealso present the fundamental properties for DSDP as well as inferencealgorithms. Simulation toy experiment and real-world experiment results forsingle and multi-cluster also support the consistency proof. This report isalso a support document for the paper ""Computationally Efficient HyperspectralData Learning Based on the Doubly Stochastic Dirichlet Process"".";
Arxiv;"Powered Dirichlet Process for Controlling the Importance of  ""Rich-Get-Richer"" Prior Assumptions in Bayesian Clustering";Ga√´l Poux-M√©dard;Julien Velcin,Sabine Loudcher;2021/04/26;http://arxiv.org/abs/2104.12485v1;"One of the most used priors in Bayesian clustering is the Dirichlet prior. Itcan be expressed as a Chinese Restaurant Process. This process allowsnonparametric estimation of the number of clusters when partitioning datasets.Its key feature is the ""rich-get-richer"" property, which assumes a cluster hasan a priori probability to get chosen linearly dependent on population. In thispaper, we show that such prior is not always the best choice to model data. Wederive the Powered Chinese Restaurant process from a modified version of theDirichlet-Multinomial distribution to answer this problem. We then develop someof its fundamental properties (expected number of clusters, convergence).Unlike state-of-the-art efforts in this direction, this new formulation allowsfor direct control of the importance of the ""rich-get-richer"" prior.";
Arxiv;Flexible clustering via hidden hierarchical Dirichlet priors;Antonio Lijoi;Igor Pr√ºnster,Giovanni Rebaudo;2022/01/18;http://arxiv.org/abs/2201.06994v1;The Bayesian approach to inference stands out for naturally allowingborrowing information across heterogeneous populations, with different samplespossibly sharing the same distribution. A popular Bayesian nonparametric modelfor clustering probability distributions is the nested Dirichlet process, whichhowever has the drawback of grouping distributions in a single cluster whenties are observed across samples. With the goal of achieving a flexible andeffective clustering method for both samples and observations, we investigate anonparametric prior that arises as the composition of two different discreterandom structures and derive a closed-form expression for the induceddistribution of the random partition, the fundamental tool regulating theclustering behavior of the model. On the one hand, this allows to gain a deeperinsight into the theoretical properties of the model and, on the other hand, ityields an MCMC algorithm for evaluating Bayesian inferences of interest.Moreover, we single out limitations of this algorithm when working with morethan two populations and, consequently, devise an alternative more efficientsampling scheme, which as a by-product, allows testing homogeneity betweendifferent populations. Finally, we perform a comparison with the nestedDirichlet process and provide illustrative examples of both synthetic and realdata.;
Arxiv;Bayesian mixture models (in)consistency for the number of clusters;Louise Alamichel;Daria Bystrova,Julyan Arbel,Guillaume Kon Kam King;2022/10/25;http://arxiv.org/abs/2210.14201v2;Bayesian nonparametric mixture models are common for modeling complex data.While these models are well-suited for density estimation, their applicationfor clustering has some limitations. Miller and Harrison (2014) provedposterior inconsistency in the number of clusters when the true number ofclusters is finite for Dirichlet process and Pitman--Yor process mixturemodels. In this work, we extend this result to additional Bayesiannonparametric priors such as Gibbs-type processes and finite-dimensionalrepresentations of them. The latter include the Dirichlet multinomial processand the recently proposed Pitman--Yor and normalized generalized gammamultinomial processes. We show that mixture models based on these processes arealso inconsistent in the number of clusters and discuss possible solutions.Notably, we show that a post-processing algorithm introduced by Guha et al.(2021) for the Dirichlet process extends to more general models and provides aconsistent method to estimate the number of components.;
Arxiv;A Bayesian View of the Poisson-Dirichlet Process;Wray Buntine;Marcus Hutter;2010/07/02;http://arxiv.org/abs/1007.0296v2;The two parameter Poisson-Dirichlet Process (PDP), a generalisation of theDirichlet Process, is increasingly being used for probabilistic modelling indiscrete areas such as language technology, bioinformatics, and image analysis.There is a rich literature about the PDP and its derivative distributions suchas the Chinese Restaurant Process (CRP). This article reviews some of the basictheory and then the major results needed for Bayesian modelling of discreteproblems including details of priors, posteriors and computation.  The PDP allows one to build distributions over countable partitions. The PDPhas two other remarkable properties: first it is partially conjugate to itself,which allows one to build hierarchies of PDPs, and second using a marginalisedrelative the CRP, one gets fragmentation and clustering properties that letsone layer partitions to build trees. This article presents the basic theory forunderstanding the notion of partitions and distributions over them, the PDP andthe CRP, and the important properties of conjugacy, fragmentation andclustering, as well as some key related properties such as consistency andconvergence. This article also presents a Bayesian interpretation of thePoisson-Dirichlet process based on an improper and infinite dimensionalDirichlet distribution. This means we can understand the process as justanother Dirichlet and thus all its sampling properties emerge naturally.  The theory of PDPs is usually presented for continuous distributions (moregenerally referred to as non-atomic distributions), however, when applied todiscrete distributions its remarkable conjugacy property emerges. This contextand basic results are also presented, as well as techniques for computing thesecond order Stirling numbers that occur in the posteriors for discretedistributions.;
Arxiv;Unsupervised Outlier Detection using Random Subspace and Subsampling  Ensembles of Dirichlet Process Mixtures;Dongwook Kim;Juyeon Park,Hee Cheol Chung,Seonghyun Jeong;2024/01/01;http://arxiv.org/abs/2401.00773v1;Probabilistic mixture models are acknowledged as a valuable tool forunsupervised outlier detection owing to their interpretability and intuitivegrounding in statistical principles. Within this framework, Dirichlet processmixture models emerge as a compelling alternative to conventional finitemixture models for both clustering and outlier detection tasks. However,despite their evident advantages, the widespread adoption of Dirichlet processmixture models in unsupervised outlier detection has been hampered bychallenges related to computational inefficiency and sensitivity to outliersduring the construction of detectors. To tackle these challenges, we propose anovel outlier detection method based on ensembles of Dirichlet process Gaussianmixtures. The proposed method is a fully unsupervised algorithm thatcapitalizes on random subspace and subsampling ensembles, not only ensuringefficient computation but also enhancing the robustness of the resultingoutlier detector. Moreover, the proposed method leverages variational inferencefor Dirichlet process mixtures to ensure efficient and fast computation.Empirical studies with benchmark datasets demonstrate that our methodoutperforms existing approaches for unsupervised outlier detection.;
Arxiv;From here to infinity - sparse finite versus Dirichlet process mixtures  in model-based clustering;Sylvia Fr√ºhwirth-Schnatter;Gertraud Malsiner-Walli;2017/06/22;http://arxiv.org/abs/1706.07194v3;In model-based-clustering mixture models are used to group data points intoclusters. A useful concept introduced for Gaussian mixtures by Malsiner Walliet al (2016) are sparse finite mixtures, where the prior distribution on theweight distribution of a mixture with $K$ components is chosen in such a waythat a priori the number of clusters in the data is random and is allowed to besmaller than $K$ with high probability. The number of cluster is then inferreda posteriori from the data.  The present paper makes the following contributions in the context of sparsefinite mixture modelling. First, it is illustrated that the concept of sparsefinite mixture is very generic and easily extended to cluster various types ofnon-Gaussian data, in particular discrete data and continuous multivariate dataarising from non-Gaussian clusters. Second, sparse finite mixtures are comparedto Dirichlet process mixtures with respect to their ability to identify thenumber of clusters. For both model classes, a random hyper prior is consideredfor the parameters determining the weight distribution. By suitable matching ofthese priors, it is shown that the choice of this hyper prior is far moreinfluential on the cluster solution than whether a sparse finite mixture or aDirichlet process mixture is taken into consideration.;
Arxiv;Flexible Priors for Exemplar-based Clustering;Daniel Tarlow;Richard S. Zemel,Brendan J. Frey;2012/06/13;http://arxiv.org/abs/1206.3294v1;"Exemplar-based clustering methods have been shown to produce state-of-the-artresults on a number of synthetic and real-world clustering problems. They areappealing because they offer computational benefits over latent-mean models andcan handle arbitrary pairwise similarity measures between data points. However,when trying to recover underlying structure in clustering problems, tailoredsimilarity measures are often not enough; we also desire control over thedistribution of cluster sizes. Priors such as Dirichlet process priors allowthe number of clusters to be unspecified while expressing priors over datapartitions. To our knowledge, they have not been applied to exemplar-basedmodels. We show how to incorporate priors, including Dirichlet process priors,into the recently introduced affinity propagation algorithm. We develop anefficient maxproduct belief propagation algorithm for our new model anddemonstrate experimentally how the expanded range of clustering priors allowsus to better recover true clusterings in situations where we have someinformation about the generating process.";
Arxiv;Parallel Clustering of Single Cell Transcriptomic Data with Split-Merge  Sampling on Dirichlet Process Mixtures;Tiehang Duan;Jos√© P. Pinto,Xiaohui Xie;2018/12/25;http://arxiv.org/abs/1812.10048v1;"Motivation: With the development of droplet based systems, massive singlecell transcriptome data has become available, which enables analysis ofcellular and molecular processes at single cell resolution and is instrumentalto understanding many biological processes. While state-of-the-art clusteringmethods have been applied to the data, they face challenges in the followingaspects: (1) the clustering quality still needs to be improved; (2) most modelsneed prior knowledge on number of clusters, which is not always available; (3)there is a demand for faster computational speed. Results: We propose to tacklethese challenges with Parallel Split Merge Sampling on Dirichlet ProcessMixture Model (the Para-DPMM model). Unlike classic DPMM methods that performsampling on each single data point, the split merge mechanism samples on thecluster level, which significantly improves convergence and optimality of theresult. The model is highly parallelized and can utilize the computing power ofhigh performance computing (HPC) clusters, enabling massive clustering on hugedatasets. Experiment results show the model outperforms current widely usedmodels in both clustering quality and computational speed. Availability: Sourcecode is publicly available onhttps://github.com/tiehangd/Para_DPMM/tree/master/Para_DPMM_package";
Arxiv;Tensor Dirichlet Process Multinomial Mixture Model for Passenger  Trajectory Clustering;Ziyue Li;Hao Yan,Chen Zhang,Andi Wang,Wolfgang Ketter,Lijun Sun,Fugee Tsung;2023/06/23;http://arxiv.org/abs/2306.13794v1;"Passenger clustering based on travel records is essential for transportationoperators. However, existing methods cannot easily cluster the passengers dueto the hierarchical structure of the passenger trip information, namely: eachpassenger has multiple trips, and each trip contains multi-dimensionalmulti-mode information. Furthermore, existing approaches rely on an accuratespecification of the clustering number to start, which is difficult whenmillions of commuters are using the transport systems on a daily basis. In thispaper, we propose a novel Tensor Dirichlet Process Multinomial Mixture model(Tensor-DPMM), which is designed to preserve the multi-mode and hierarchicalstructure of the multi-dimensional trip information via tensor, and clusterthem in a unified one-step manner. The model also has the ability to determinethe number of clusters automatically by using the Dirichlet Process to decidethe probabilities for a passenger to be either assigned in an existing clusteror to create a new cluster: This allows our model to grow the clusters asneeded in a dynamic manner. Finally, existing methods do not consider spatialsemantic graphs such as geographical proximity and functional similaritybetween the locations, which may cause inaccurate clustering. To this end, wefurther propose a variant of our model, namely the Tensor-DPMM with Graph. Forthe algorithm, we propose a tensor Collapsed Gibbs Sampling method, with aninnovative step of ""disband and relocating"", which disbands clusters with toosmall amount of members and relocates them to the remaining clustering. Thisavoids uncontrollable growing amounts of clusters. A case study based on HongKong metro passenger data is conducted to demonstrate the automatic process oflearning the number of clusters, and the learned clusters are better inwithin-cluster compactness and cross-cluster separateness.";
Arxiv;Hierarchical Latent Word Clustering;Halid Ziya Yerebakan;Fitsum Reda,Yiqiang Zhan,Yoshihisa Shinagawa;2016/01/20;http://arxiv.org/abs/1601.05472v1;This paper presents a new Bayesian non-parametric model by extending theusage of Hierarchical Dirichlet Allocation to extract tree structured wordclusters from text data. The inference algorithm of the model collects words ina cluster if they share similar distribution over documents. In ourexperiments, we observed meaningful hierarchical structures on NIPS corpus andradiology reports collected from public repositories.;
Arxiv;An efficient algorithm for solving elliptic problems on percolation  clusters;Chenlin Gu;;2019/07/31;http://arxiv.org/abs/1907.13571v1;We present an efficient algorithm to solve elliptic Dirichlet problemsdefined on the cluster of $\mathbb{Z}^d$ supercritical Bernoulli percolation,as a generalization of the iterative method proposed by S. Armstrong, A.Hannukainen, T. Kuusi and J.-C. Mourrat. We also explore the two-scaleexpansion on the infinite cluster of percolation, and use it to give a rigorousanalysis of the algorithm.;
Arxiv;Colouring and breaking sticks: random distributions and heterogeneous  clustering;Peter J. Green;;2010/03/21;http://arxiv.org/abs/1003.3988v1;We begin by reviewing some probabilistic results about the Dirichlet Processand its close relatives, focussing on their implications for statisticalmodelling and analysis. We then introduce a class of simple mixture models inwhich clusters are of different `colours', with statistical characteristicsthat are constant within colours, but different between colours. Thus clusteridentities are exchangeable only within colours. The basic form of our model isa variant on the familiar Dirichlet process, and we find that much of thestandard modelling and computational machinery associated with the Dirichletprocess may be readily adapted to our generalisation. The methodology isillustrated with an application to the partially-parametric clustering of geneexpression profiles.;
Arxiv;Beta-Product Poisson-Dirichlet Processes;Federico Bassetti;Roberto Casarin,Fabrizio Leisen;2011/09/22;http://arxiv.org/abs/1109.4777v1;Time series data may exhibit clustering over time and, in a multiple timeseries context, the clustering behavior may differ across the series. Thispaper is motivated by the Bayesian non--parametric modeling of the dependencebetween the clustering structures and the distributions of different timeseries. We follow a Dirichlet process mixture approach and introduce a newclass of multivariate dependent Dirichlet processes (DDP). The proposed DDP arerepresented in terms of vector of stick-breaking processes with dependentweights. The weights are beta random vectors that determine different anddependent clustering effects along the dimension of the DDP vector. We discusssome theoretical properties and provide an efficient Monte Carlo Markov Chainalgorithm for posterior computation. The effectiveness of the method isillustrated with a simulation study and an application to the United States andthe European Union industrial production indexes.;
Arxiv;Conjoined Dirichlet Process;Michelle N. Ngo;Dustin S. Pluta,Alexander N. Ngo,Babak Shahbaba;2020/02/08;http://arxiv.org/abs/2002.03223v1;Biclustering is a class of techniques that simultaneously clusters the rowsand columns of a matrix to sort heterogeneous data into homogeneous blocks.Although many algorithms have been proposed to find biclusters, existingmethods suffer from the pre-specification of the number of biclusters or placeconstraints on the model structure. To address these issues, we develop anovel, non-parametric probabilistic biclustering method based on Dirichletprocesses to identify biclusters with strong co-occurrence in both rows andcolumns. The proposed method utilizes dual Dirichlet process mixture models tolearn row and column clusters, with the number of resulting clusters determinedby the data rather than pre-specified. Probabilistic biclusters are identifiedby modeling the mutual dependence between the row and column clusters. We applyour method to two different applications, text mining and gene expressionanalysis, and demonstrate that our method improves bicluster extraction in manysettings compared to existing approaches.;
Arxiv;On the Variational Posterior of Dirichlet Process Deep Latent Gaussian  Mixture Models;Amine Echraibi;Joachim Flocon-Cholet,St√©phane Gosselin,Sandrine Vaton;2020/06/16;http://arxiv.org/abs/2006.08993v2;Thanks to the reparameterization trick, deep latent Gaussian models haveshown tremendous success recently in learning latent representations. Theability to couple them however with nonparamet-ric priors such as the DirichletProcess (DP) hasn't seen similar success due to its non parameteriz-ablenature. In this paper, we present an alternative treatment of the variationalposterior of the Dirichlet Process Deep Latent Gaussian Mixture Model(DP-DLGMM), where we show that the prior cluster parameters and the variationalposteriors of the beta distributions and cluster hidden variables can beupdated in closed-form. This leads to a standard reparameterization trick onthe Gaussian latent variables knowing the cluster assignments. We demonstrateour approach on standard benchmark datasets, we show that our model is capableof generating realistic samples for each cluster obtained, and manifestscompetitive performance in a semi-supervised setting.;
Arxiv;Powered Hawkes-Dirichlet Process: Challenging Textual Clustering using a  Flexible Temporal Prior;Ga√´l Poux-M√©dard;Julien Velcin,Sabine Loudcher;2021/09/15;http://arxiv.org/abs/2109.07170v1;The textual content of a document and its publication date are intertwined.For example, the publication of a news article on a topic is influenced byprevious publications on similar issues, according to underlying temporaldynamics. However, it can be challenging to retrieve meaningful informationwhen textual information conveys little information or when temporal dynamicsare hard to unveil. Furthermore, the textual content of a document is notalways linked to its temporal dynamics. We develop a flexible method to createclusters of textual documents according to both their content and publicationtime, the Powered Dirichlet-Hawkes process (PDHP). We show PDHP yieldssignificantly better results than state-of-the-art models when temporalinformation or textual content is weakly informative. The PDHP also alleviatesthe hypothesis that textual content and temporal dynamics are always perfectlycorrelated. PDHP allows retrieving textual clusters, temporal clusters, or amixture of both with high accuracy when they are not. We demonstrate that PDHPgeneralizes previous work --such as the Dirichlet-Hawkes process (DHP) andUniform process (UP). Finally, we illustrate the changes induced by PDHP overDHP and UP in a real-world application using Reddit data.;
Arxiv;Similarity-based Random Partition Distribution for Clustering Functional  Data;Tomoya Wakayama;Shonosuke Sugasawa,Genya Kobayashi;2023/08/03;http://arxiv.org/abs/2308.01704v2;Random partition distribution is a crucial tool for model-based clustering.This study advances the field of random partition in the context of functionalspatial data, focusing on the challenges posed by hourly population data acrossvarious regions and dates. We propose an extended generalized Dirichletprocess, named the similarity-based generalized Dirichlet process (SGDP), toaddress the limitations of simple random partition distributions (e.g., thoseinduced by the Dirichlet process), such as an overabundance of clusters. Thismodel prevents producing excess clusters as well as incorporates pairwisesimilarity information to ensure a more accurate and meaningful grouping. Thetheoretical properties of SGDP are studied. Then, SGDP is applied to areal-world dataset of hourly population flows in 500$\rm{m}^2$ meshes in thecentral part of Tokyo. In this empirical context, SGDP excelled at detectingmeaningful patterns in the data while accounting for spatial nuances. Theresults underscore the adaptability and utility of the method, showcasing itsprowess in revealing intricate spatiotemporal dynamics. This study's findingscontribute significantly to urban planning, transportation, and policy-makingby providing a helpful tool for understanding population dynamics and theirimplications.;
Arxiv;Nonparametric Variable Selection, Clustering and Prediction for  High-Dimensional Regression;Subharup Guha;Veerabhadran Baladandayuthapani;2014/07/21;http://arxiv.org/abs/1407.5472v3;The development of parsimonious models for reliable inference and predictionof responses in high-dimensional regression settings is often challenging dueto relatively small sample sizes and the presence of complex interactionpatterns between a large number of covariates. We propose an efficient,nonparametric framework for simultaneous variable selection, clustering andprediction in high-throughput regression settings with continuous or discreteoutcomes, called VariScan. The VariScan model utilizes the sparsity induced byPoisson-Dirichlet processes (PDPs) to group the covariates intolower-dimensional latent clusters consisting of covariates with similarpatterns among the samples. The data are permitted to direct the choice of asuitable cluster allocation scheme, choosing between PDPs and their specialcase, a Dirichlet process. Subsequently, the latent clusters are used to builda nonlinear prediction model for the responses using an adaptive mixture oflinear and nonlinear elements, thus achieving a balance between model parsimonyand flexibility. We investigate theoretical properties of the VariScanprocedure that differentiate the allocations patterns of PDPs and Dirichletprocesses both in terms of the number and relative sizes of their clusters.Additional theoretical results guarantee the high accuracy of the model-basedclustering procedure, and establish model selection and prediction consistency.Through simulation studies and analyses of benchmark data sets, we demonstratethe reliability of VariScan's clustering mechanism and show that the techniquecompares favorably to, and often outperforms, existing methodologies in termsof the prediction accuracies of the subject-specific responses.;
Arxiv;Fair Clustering via Hierarchical Fair-Dirichlet Process;Abhisek Chakraborty;Anirban Bhattacharya,Debdeep Pati;2023/05/27;http://arxiv.org/abs/2305.17557v1;The advent of ML-driven decision-making and policy formation has led to anincreasing focus on algorithmic fairness. As clustering is one of the mostcommonly used unsupervised machine learning approaches, there has naturallybeen a proliferation of literature on {\em fair clustering}. A popular notionof fairness in clustering mandates the clusters to be {\em balanced}, i.e.,each level of a protected attribute must be approximately equally representedin each cluster. Building upon the original framework, this literature hasrapidly expanded in various aspects. In this article, we offer a novelmodel-based formulation of fair clustering, complementing the existingliterature which is almost exclusively based on optimizing appropriateobjective functions.;
Arxiv;DIVA: A Dirichlet Process Mixtures Based Incremental Deep Clustering  Algorithm via Variational Auto-Encoder;Zhenshan Bing;Yuan Meng,Yuqi Yun,Hang Su,Xiaojie Su,Kai Huang,Alois Knoll;2023/05/23;http://arxiv.org/abs/2305.14067v3;"Generative model-based deep clustering frameworks excel in classifyingcomplex data, but are limited in handling dynamic and complex features becausethey require prior knowledge of the number of clusters. In this paper, wepropose a nonparametric deep clustering framework that employs an infinitemixture of Gaussians as a prior. Our framework utilizes a memoized onlinevariational inference method that enables the ""birth"" and ""merge"" moves ofclusters, allowing our framework to cluster data in a ""dynamic-adaptive""manner, without requiring prior knowledge of the number of features. We namethe framework as DIVA, a Dirichlet Process-based Incremental deep clusteringframework via Variational Auto-Encoder. Our framework, which outperformsstate-of-the-art baselines, exhibits superior performance in classifyingcomplex data with dynamically changing features, particularly in the case ofincremental features. We released our source code implementation at:https://github.com/Ghiara/diva";
Arxiv;Product Centered Dirichlet Processes for Dependent Clustering;Alexander Dombowsky;David B. Dunson;2023/12/08;http://arxiv.org/abs/2312.05365v1;While there is an immense literature on Bayesian methods for clustering, themultiview case has received little attention. This problem focuses on obtainingdistinct but statistically dependent clusterings in a common set of entitiesfor different data types. For example, clustering patients into subgroups withsubgroup membership varying according to the domain of the patient variables. Achallenge is how to model the across-view dependence between the partitions ofpatients into subgroups. The complexities of the partition space make standardmethods to model dependence, such as correlation, infeasible. In this article,we propose CLustering with Independence Centering (CLIC), a clustering priorthat uses a single parameter to explicitly model dependence between clusteringsacross views. CLIC is induced by the product centered Dirichlet process (PCDP),a novel hierarchical prior that bridges between independent and equivalentpartitions. We show appealing theoretic properties, provide a finiteapproximation and prove its accuracy, present a marginal Gibbs sampler forposterior computation, and derive closed form expressions for the marginal andjoint partition distributions for the CLIC model. On synthetic data and in anapplication to epidemiology, CLIC accurately characterizes view-specificpartitions while providing inference on the dependence level.;
Arxiv;Invariant Percolation and Harmonic Dirichlet Functions;Damien Gaboriau;;2004/05/24;http://arxiv.org/abs/math/0405458v3;The main goal of this paper is to answer question 1.10 and settle conjecture1.11 of Benjamini-Lyons-Schramm [BLS99] relating harmonic Dirichlet functionson a graph to those of the infinite clusters in the uniqueness phase ofBernoulli percolation. We extend the result to more general invariantpercolations, including the Random-Cluster model. We prove the existence of thenonuniqueness phase for the Bernoulli percolation (and make some progress forRandom-Cluster model) on unimodular transitive locally finite graphs admittingnonconstant harmonic Dirichlet functions. This is done by using the device of$\ell^2$ Betti numbers.;
Arxiv;Bayesian Nonparametric Multilevel Clustering with Group-Level Contexts;Vu Nguyen;Dinh Phung,XuanLong Nguyen,Svetha Venkatesh,Hung Hai Bui;2014/01/09;http://arxiv.org/abs/1401.1974v4;We present a Bayesian nonparametric framework for multilevel clustering whichutilizes group-level context information to simultaneously discoverlow-dimensional structures of the group contents and partitions groups intoclusters. Using the Dirichlet process as the building block, our modelconstructs a product base-measure with a nested structure to accommodatecontent and context observations at multiple levels. The proposed modelpossesses properties that link the nested Dirichlet processes (nDP) and theDirichlet process mixture models (DPM) in an interesting way: integrating outall contents results in the DPM over contexts, whereas integrating outgroup-specific contexts results in the nDP mixture over content variables. Weprovide a Polya-urn view of the model and an efficient collapsed Gibbsinference procedure. Extensive experiments on real-world datasets demonstratethe advantage of utilizing context information via our model in both text andimage domains.;
Arxiv;Choose A Table: Tensor Dirichlet Process Multinomial Mixture Model with  Graphs for Passenger Trajectory Clustering;Ziyue Li;Hao Yan,Chen Zhang,Lijun Sun,Wolfgang Ketter,Fugee Tsung;2023/10/31;http://arxiv.org/abs/2310.20224v1;Passenger clustering based on trajectory records is essential fortransportation operators. However, existing methods cannot easily cluster thepassengers due to the hierarchical structure of the passenger trip information,including multiple trips within each passenger and multi-dimensionalinformation about each trip. Furthermore, existing approaches rely on anaccurate specification of the clustering number to start. Finally, existingmethods do not consider spatial semantic graphs such as geographical proximityand functional similarity between the locations. In this paper, we propose anovel tensor Dirichlet Process Multinomial Mixture model with graphs, which canpreserve the hierarchical structure of the multi-dimensional trip informationand cluster them in a unified one-step manner with the ability to determine thenumber of clusters automatically. The spatial graphs are utilized in communitydetection to link the semantic neighbors. We further propose a tensor versionof Collapsed Gibbs Sampling method with a minimum cluster size requirement. Acase study based on Hong Kong metro passenger data is conducted to demonstratethe automatic process of cluster amount evolution and better cluster qualitymeasured by within-cluster compactness and cross-cluster separateness. The codeis available at https://github.com/bonaldli/TensorDPMM-G.;
Arxiv;Gibbs Sampling for (Coupled) Infinite Mixture Models in the Stick  Breaking Representation;Ian Porteous;Alexander T. Ihler,Padhraic Smyth,Max Welling;2012/06/27;http://arxiv.org/abs/1206.6845v1;Nonparametric Bayesian approaches to clustering, information retrieval,language modeling and object recognition have recently shown great promise as anew paradigm for unsupervised data analysis. Most contributions have focused onthe Dirichlet process mixture models or extensions thereof for which efficientGibbs samplers exist. In this paper we explore Gibbs samplers for infinitecomplexity mixture models in the stick breaking representation. The advantageof this representation is improved modeling flexibility. For instance, one candesign the prior distribution over cluster sizes or couple multiple infinitemixture models (e.g. over time) at the level of their parameters (i.e. thedependent Dirichlet process model). However, Gibbs samplers for infinitemixture models (as recently introduced in the statistics literature) seem tomix poorly over cluster labels. Among others issues, this can have the adverseeffect that labels for the same cluster in coupled mixture models are mixed up.We introduce additional moves in these samplers to improve mixing over clusterlabels and to bring clusters into correspondence. An application to modeling ofstorm trajectories is used to illustrate these ideas.;
Arxiv;Functional clustering in nested designs: Modeling variability in  reproductive epidemiology studies;Abel Rodriguez;David B. Dunson;2014/11/20;http://arxiv.org/abs/1411.5510v1;We discuss functional clustering procedures for nested designs, wheremultiple curves are collected for each subject in the study. We start byconsidering the application of standard functional clustering tools to thisproblem, which leads to groupings based on the average profile for eachsubject. After discussing some of the shortcomings of this approach, we presenta mixture model based on a generalization of the nested Dirichlet process thatclusters subjects based on the distribution of their curves. By using mixturesof generalized Dirichlet processes, the model induces a much more flexibleprior on the partition structure than other popular model-based clusteringmethods, allowing for different rates of introduction of new clusters as thenumber of observations increases. The methods are illustrated using hormoneprofiles from multiple menstrual cycles collected for women in the EarlyPregnancy Study.;
Arxiv;Posterior Distribution for the Number of Clusters in Dirichlet Process  Mixture Models;Chiao-Yu Yang;Eric Xia,Nhat Ho,Michael I. Jordan;2019/05/23;http://arxiv.org/abs/1905.09959v2;Dirichlet process mixture models (DPMM) play a central role in Bayesiannonparametrics, with applications throughout statistics and machine learning.DPMMs are generally used in clustering problems where the number of clusters isnot known in advance, and the posterior distribution is treated as providinginference for this number. Recently, however, it has been shown that the DPMMis inconsistent in inferring the true number of components in certain cases.This is an asymptotic result, and it would be desirable to understand whetherit holds with finite samples, and to more fully understand the full posterior.In this work, we provide a rigorous study for the posterior distribution of thenumber of clusters in DPMM under different prior distributions on theparameters and constraints on the distributions of the data. We provide novellower bounds on the ratios of probabilities between $s+1$ clusters and $s$clusters when the prior distributions on parameters are chosen to be Gaussianor uniform distributions.;
Arxiv;Bayesian nonparametric temporal dynamic clustering via autoregressive  Dirichlet priors;Maria De Iorio;Stefano Favaro,Alessandra Guglielmi,Lifeng Ye;2019/10/23;http://arxiv.org/abs/1910.10443v1;"In this paper we consider the problem of dynamic clustering, where clustermemberships may change over time and clusters may split and merge over time,thus creating new clusters and destroying existing ones. We propose a Bayesiannonparametric approach to dynamic clustering via mixture modeling. Our approachrelies on a novel time-dependent nonparametric prior defined by combining: i) acopula-based transformation of a Gaussian autoregressive process; ii) thestick-breaking construction of the Dirichlet process. Posterior inference isperformed through a particle Markov chain Monte Carlo algorithm which issimple, computationally efficient and scalable to massive datasets. Advantagesof the proposed approach include flexibility in applications, ease ofcomputations and interpretability. We present an application of our dynamicBayesian nonparametric mixture model to the study the temporal dynamics ofgender stereotypes in adjectives and occupations in the 20th and 21st centuriesin the United States. Moreover, to highlight the flexibility of our model wepresent additional applications to time-dependent data with covariates and withspatial structure.";
Arxiv;Topic Detection from Conversational Dialogue Corpus with Parallel  Dirichlet Allocation Model and Elbow Method;Haider Khalid;Vincent Wade;2020/06/05;http://arxiv.org/abs/2006.03353v1;A conversational system needs to know how to switch between topics tocontinue the conversation for a more extended period. For this topic detectionfrom dialogue corpus has become an important task for a conversation andaccurate prediction of conversation topics is important for creating coherentand engaging dialogue systems. In this paper, we proposed a topic detectionapproach with Parallel Latent Dirichlet Allocation (PLDA) Model by clustering avocabulary of known similar words based on TF-IDF scores and Bag of Words (BOW)technique. In the experiment, we use K-mean clustering with Elbow Method forinterpretation and validation of consistency within-cluster analysis to selectthe optimal number of clusters. We evaluate our approach by comparing it withtraditional LDA and clustering technique. The experimental results show thatcombining PLDA with Elbow method selects the optimal number of clusters andrefine the topics for the conversation.;
Arxiv;Joint Clustering and Registration of Functional Data;Yafeng Zhang;Donatello Telesca;2014/03/27;http://arxiv.org/abs/1403.7134v1;Curve registration and clustering are fundamental tools in the analysis offunctional data. While several methods have been developed and explored foreither task individually, limited work has been done to infer functionalclusters and register curves simultaneously. We propose a hierarchical modelfor joint curve clustering and registration. Our proposal combines a Dirichletprocess mixture model for clustering of common shapes, with a reproducingkernel representation of phase variability for registration. We show howinference can be carried out applying standard posterior simulation algorithmsand compare our method to several alternatives in both engineered data and abenchmark analysis of the Berkeley growth data. We conclude our investigationwith an application to time course gene expression.;
Arxiv;Heterogeneous Regression Models for Clusters of Spatial Dependent Data;Zhihua Ma;Yishu Xue,Guanyu Hu;2019/07/04;http://arxiv.org/abs/1907.02212v4;In economic development, there are often regions that share similar economiccharacteristics, and economic models on such regions tend to have similarcovariate effects. In this paper, we propose a Bayesian clustered regressionfor spatially dependent data in order to detect clusters in the covariateeffects. Our proposed method is based on the Dirichlet process which provides aprobabilistic framework for simultaneous inference of the number of clustersand the clustering configurations. The usage of our method is illustrated bothin simulation studies and an application to a housing cost dataset of Georgia.;
Arxiv;Dirichlet Fragmentation Processes;Hong Ge;Yarin Gal,Zoubin Ghahramani;2015/09/16;http://arxiv.org/abs/1509.04781v1;Tree structures are ubiquitous in data across many domains, and many datasetsare naturally modelled by unobserved tree structures. In this paper, first wereview the theory of random fragmentation processes [Bertoin, 2006], and anumber of existing methods for modelling trees, including the popular nestedChinese restaurant process (nCRP). Then we define a general class ofprobability distributions over trees: the Dirichlet fragmentation process (DFP)through a novel combination of the theory of Dirichlet processes and randomfragmentation processes. This DFP presents a stick-breaking construction, andrelates to the nCRP in the same way the Dirichlet process relates to theChinese restaurant process. Furthermore, we develop a novel hierarchicalmixture model with the DFP, and empirically compare the new model to similarmodels in machine learning. Experiments show the DFP mixture model to beconvincingly better than existing state-of-the-art approaches for hierarchicalclustering and density modelling.;
Arxiv;The semi-hierarchical Dirichlet Process and its application to  clustering homogeneous distributions;Mario Beraha;Alessandra Guglielmi,Fernando A. Quintana;2020/05/20;http://arxiv.org/abs/2005.10287v4;"Assessing homogeneity of distributions is an old problem that has receivedconsiderable attention, especially in the nonparametric Bayesian literature. Tothis effect, we propose the semi-hierarchical Dirichlet process, a novelhierarchical prior that extends the hierarchical Dirichlet process of Teh etal. (2006) and that avoids the degeneracy issues of nested processes recentlydescribed by Camerlenghi et al. (2019a). We go beyond the simple yes/no answerto the homogeneity question and embed the proposed prior in a random partitionmodel; this procedure allows us to give a more comprehensive response to theabove question and in fact find groups of populations that are internallyhomogeneous when I greater or equal than 2 such populations are considered. Westudy theoretical properties of the semi-hierarchical Dirichlet process and ofthe Bayes factor for the homogeneity test when I = 2. Extensive simulationstudies and applications to educational data are also discussed.";
